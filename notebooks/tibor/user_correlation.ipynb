{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import timedelta, datetime\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Path(\"/media/hpi_share/\")#Path(\"//FS23/projekte$/MP2021/MPWS2021/MPWS2021FN1\")\n",
    "mp_drive_dir = Path(\"../../../\")\n",
    "mp_plot_dir = mp_drive_dir / \"plots\"\n",
    "input_path = Path(\"../../matched-infoboxes-extracted/\")\n",
    "input_data = list(input_path.rglob(\"*.json\"))\n",
    "files = [x for x in input_data if x.is_file()]\n",
    "len(files)  # total 580\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_iteratons = 1\n",
    "number_of_files = 5\n",
    "number_of_files_start = 5\n",
    "num_edits = 0\n",
    "num_change_tuples = 0\n",
    "typo_lst = []\n",
    "for _ in range(num_iteratons):\n",
    "    revision_tuples = []\n",
    "    change_tuples = []\n",
    "    for file in tqdm(files[number_of_files_start:number_of_files_start+number_of_files]):\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            for jsonObj in f:\n",
    "                single_edit = json.loads(jsonObj)\n",
    "                num_edits += 1\n",
    "                title = single_edit['pageTitle']\n",
    "                pageID = single_edit['pageID']\n",
    "                key = single_edit['key']\n",
    "                template = single_edit['template'] if 'template' in single_edit.keys(\n",
    "                ) else None\n",
    "                changes = single_edit['changes']\n",
    "                validFrom = single_edit['validFrom']\n",
    "                revisionId = single_edit['revisionId']\n",
    "                changeType = single_edit['type']\n",
    "                attributes = single_edit['attributes'] if 'attributes' in single_edit.keys(\n",
    "                ) else None\n",
    "                user_name = single_edit['user']['username'] if 'username' in single_edit['user'].keys(\n",
    "                ) else None\n",
    "                user_id = single_edit['user']['id'] if 'id' in single_edit['user'].keys(\n",
    "                ) else None\n",
    "                user_ip = single_edit['user']['ip'] if 'ip' in single_edit['user'].keys(\n",
    "                ) else None\n",
    "                revision_tuples.append(\n",
    "                    (title, pageID, key, template, name, revisionId, changeType, user_name, user_id, user_ip, attributes))\n",
    "\n",
    "                for change in changes:\n",
    "                    num_change_tuples += 1\n",
    "                    name = change['property']['name']\n",
    "                    current_value = change['currentValue'] if 'currentValue' in change.keys(\n",
    "                    ) else None\n",
    "                    previous_value = change['previousValue'] if 'previousValue' in change.keys(\n",
    "                    ) else None\n",
    "                    validTo = change['valueValidTo'] if 'valueValidTo' in change.keys(\n",
    "                    ) else None\n",
    "                    change_tuples.append((title, pageID, key, template, name, previous_value,\n",
    "                                          current_value, validFrom, validTo, revisionId, changeType, user_name, user_id, user_ip, attributes))\n",
    "    number_of_files_start += number_of_files\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data = pd.DataFrame(change_tuples, columns=['key', 'pageID', 'title', 'user','name', 'previous_value', 'current_value', 'timestamp', 'edit_type'])\n",
    "# data['timestamp'] = pd.to_datetime(data['timestamp']).dt.tz_localize(None)\n",
    "data = pd.DataFrame(change_tuples, columns=['pageTitle', 'pageID', 'key', 'template', 'name', 'previous_value',\n",
    "                    'current_value', 'validFrom', 'validTo', 'revisionId', 'change_type', 'user_name', 'user_id', 'user_ip', 'attributes'])\n",
    "data['validFrom'] = pd.to_datetime(data['validFrom'])\n",
    "data['validTo'] = pd.to_datetime(data['validTo'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.head(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Unique user ids:\", data['user_id'].nunique())\n",
    "print(\"Unique user ips:\", data['user_ip'].nunique())\n",
    "print(\"Unique users (unique ip/id combinations):\", len(data[['user_id', 'user_ip']].drop_duplicates())) #including both NaN/None\n",
    "#data['user_id'].nunique()+data['user_ip'].nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# user ids and ips are none?\n",
    "data.query('user_id.isnull() and user_ip.isnull()').head(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Mostly Deletes and Update have no user\n",
    "data.query('user_id.isnull() and user_ip.isnull()').groupby('change_type').count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sanity check if one revid has one user\n",
    "data[[\"revisionId\",\"user_id\",\"user_ip\"]].groupby(\"revisionId\").nunique().head(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data[[\"revisionId\",\"user_id\",\"user_ip\"]].groupby([\"user_id\",\"user_ip\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_revs = pd.DataFrame(revision_tuples, columns=['pageTitle', 'pageID', 'key', 'template', 'name', 'revisionId', 'change_type', 'user_name', 'user_id', 'user_ip', 'attributes'])\n",
    "data_revs.head(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"max creations/updates/deletions of a single user\")\n",
    "print(\"Create\",data_revs.query('change_type==\"CREATE\"').groupby(\"user_id\").count()['revisionId'].max())\n",
    "print(\"Delete\",data_revs.query('change_type==\"DELETE\"').groupby(\"user_id\").count()['revisionId'].max())\n",
    "print(\"Update\",data_revs.query('change_type==\"UPDATE\"').groupby(\"user_id\").count()['revisionId'].max())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- How many different pages a user works on\n",
    "- how many different users work on a single page\n",
    "- at which time a user makes changes\n",
    "- does a user make changes in a specific order multiple times"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('mp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "9d6890af0e7111529245105513a4571ecfc3e378a026bfe7b711a2eb3eb8eca5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}