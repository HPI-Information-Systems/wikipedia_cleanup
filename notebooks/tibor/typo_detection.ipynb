{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import matplotlib.pyplot as plt\n",
    "import fastDamerauLevenshtein"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How does it work\n",
    "Typos:\n",
    "- previous and current values are splittet into words with non letters/whitespaces removed, if any are None or empty they are skipped\n",
    "- only same wordcounts are tested (it is expected that words stay in the same order)\n",
    "- words are compared to the words with the same index with Damerau-Levenshtein edit distance (swaps are cost 1 not 2)\n",
    "- if any word has edit distance 1 or 2 it is further looked at\n",
    "    1. test if first letter is a case swap (it is expected the user knows what is correct)\n",
    "    2. test if previous word is not in a dictionary but current word is (comparison is done in lowercase)\n",
    "- if any of the tests is true the change is marked as typo-fix\n",
    "\n",
    "Swear words:\n",
    "- previous and current values are splittet into words, if any are None or empty they are skipped\n",
    "- words are compared to a swear word dictionary (https://github.com/RobertJGabriel/Google-profanity-words/blob/master/list.txt)\n",
    "- if any word is matched the value is flagged as swear word\n",
    "- if previous value has no swear word but current value has -> swear word added\n",
    "- if previous value has a swear word but current value has not -> swear word deleted"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# splits string in words\n",
    "def split_strings(str1, str2):\n",
    "    lst = [str1.split()]\n",
    "    lst.append(str2.split())\n",
    "    return lst\n",
    "\n",
    "# checks if wordcount in both strings is equal\n",
    "\n",
    "\n",
    "def same_wordcounts(lst1, lst2):\n",
    "    return (len(lst1) == len(lst2))\n",
    "\n",
    "# deletes non alphabetical characters from string\n",
    "\n",
    "\n",
    "def skip_no_alpha(string):\n",
    "    only_alpha = \"\"\n",
    "    for char in string:\n",
    "        if char.isalpha() or char == \" \":\n",
    "            only_alpha += char\n",
    "    return only_alpha\n",
    "\n",
    "# checks in numbers are increments\n",
    "\n",
    "\n",
    "def is_increment(nr1, nr2):\n",
    "    return (nr1+1 == nr2 or nr1-1 == nr2)\n",
    "\n",
    "# checks if case (upper/loewr) of the first latter is switched\n",
    "\n",
    "\n",
    "def is_first_letter_caseswitch(str1, str2):\n",
    "    return (str1[0].isupper() and str2[0].islower() or str1[0].islower() and str2[0].isupper())\n",
    "\n",
    "\n",
    "def is_not_empty_or_none(input):\n",
    "    return input is not None and input is not \"\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_levenshtein_dists(lst1, lst2):\n",
    "    if len(lst1) != len(lst2):\n",
    "        print(\"Difference words counts of lists!\")\n",
    "        return\n",
    "    dists = []\n",
    "    for i in range(len(lst1)):\n",
    "            dists.append(int(fastDamerauLevenshtein.damerauLevenshtein(\n",
    "                lst1[i], lst2[i], similarity=False)))\n",
    "    return dists\n",
    "\n",
    "# splits strings in words\n",
    "def get_words_and_dists(str1, str2, only_alpha=False):\n",
    "    if only_alpha:\n",
    "        str1=skip_no_alpha(str1)\n",
    "        str2=skip_no_alpha(str2)\n",
    "    words = split_strings(str1, str2)\n",
    "    if len(words[0]) == len(words[1]):\n",
    "        dists = get_levenshtein_dists(words[0], words[1])\n",
    "    else:\n",
    "        dists = []\n",
    "    return words, dists\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def word_in_dict(str1, words_dict):\n",
    "    return str1 in words_dict\n",
    "\n",
    "def is_typo_fixed(str1, str2, words_dict, lowercase=True):\n",
    "    \"\"\" Check if typo is fixed.\n",
    "        return 0: no other case is found\n",
    "        return 1: word was not in dict before (missspelled)\n",
    "        return 2: word with swapped first letter (and other changes depending on edit distance)\n",
    "    \"\"\"\n",
    "    # detects number errors (dreher,tippfehler), skipps increments. Only works if skip_no_alpha is false \n",
    "    if str1.isdigit() and str2.isdigit() and not is_increment(int(str1),int(str2)):\n",
    "        return 3\n",
    "\n",
    "    if is_first_letter_caseswitch(str1,str2):\n",
    "        return 2\n",
    "\n",
    "    if lowercase:\n",
    "        str1=str1.lower()\n",
    "        str2=str2.lower()\n",
    "\n",
    "    # checks if str1 is not in dict but str2 is\n",
    "    if (not word_in_dict(str1, words_dict) and word_in_dict(str2, words_dict)):\n",
    "        return 1\n",
    "        \n",
    "    return 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_typo_type(str1, str2, words_dict, upper_lev_distance=2, skip_no_alpha=False):\n",
    "    words, levenshtein_dists = get_words_and_dists(\n",
    "        str1, str2, skip_no_alpha)\n",
    "    typo_lst = []\n",
    "    for i in range(len(levenshtein_dists)):  # only loops if dists are found (word counts are equal)\n",
    "        # only uses distances >0 <=2\n",
    "        if(levenshtein_dists[i] > 0 and levenshtein_dists[i] <= upper_lev_distance):\n",
    "            typo_lst.append(is_typo_fixed(\n",
    "                words[0][i], words[1][i], words_dict))\n",
    "        # else:  # appends None if dist is <0 or >2\n",
    "        #     typo_lst.append(None)\n",
    "    return typo_lst\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "my_file = open(\"../../../words_alpha.txt\", \"r\")\n",
    "words_dict=set(my_file.read().split(\"\\n\"))\n",
    "\n",
    "testcase1 = [\"Hier sind kkeine Fheler\", \"Hier sind keine Fehler\"]\n",
    "testcase1_en = [\"There are nno erorrs\", \"There are no errors\"]\n",
    "typo_lst = get_typo_type(testcase1_en[0], testcase1_en[1], words_dict)\n",
    "print(typo_lst)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def typo_check(str1, str2, words_dict, upper_lev_distance=2, skip_no_alpha=False):\n",
    "    \"\"\"Return True if typo\n",
    "       Return False if no typo\n",
    "    \"\"\"\n",
    "    typo_lst = get_typo_type(str1, str2, words_dict, upper_lev_distance, skip_no_alpha)\n",
    "    if len(typo_lst) == 0:\n",
    "        return None\n",
    "    for typo_type in typo_lst:\n",
    "        if typo_type > 0:  # 1 is previous not in dict, current is in dict, 2 case switch on first letter\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def typo_check_pandas(row, words_dict, upper_lev_distance=2, skip_no_alpha=False):\n",
    "    \"\"\"Return True if typo\n",
    "       Return False if no typo\n",
    "    \"\"\"\n",
    "    typo_lst = get_typo_type(row[\"currentValue\"], row[\"previousValue\"], words_dict, upper_lev_distance, skip_no_alpha)\n",
    "    if len(typo_lst) == 0:\n",
    "        return None\n",
    "    for typo_type in typo_lst:\n",
    "        if typo_type > 0:  # 1 is previous not in dict, current is in dict, 2 case switch on first letter\n",
    "            return True\n",
    "    return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "def swear_check(str1, str2, words_dict, lowercase=True):\n",
    "    \"\"\" Check if swear got added or removed.\n",
    "        Input:\n",
    "            str1: prev string\n",
    "            str2: curr string\n",
    "        Output:\n",
    "        prev false , curr true : 1 (swear word added)\n",
    "        prev true , curr false : 2 (swear word removed)\n",
    "    \"\"\"\n",
    "    if lowercase:\n",
    "        str1=str1.lower()\n",
    "        str2=str2.lower()\n",
    "\n",
    "    str1_lst=str1.split()\n",
    "    str2_lst=str2.split()\n",
    "\n",
    "    prev_swear=False\n",
    "    curr_swear=False\n",
    "    for string in str1_lst:\n",
    "        if word_in_dict(string, words_dict):\n",
    "            prev_swear=True\n",
    "            break\n",
    "\n",
    "    for string in str2_lst:\n",
    "        if word_in_dict(string, words_dict):\n",
    "            curr_swear=True\n",
    "            break\n",
    "\n",
    "    if (not prev_swear and curr_swear):\n",
    "        # swear word added\n",
    "        return 1\n",
    "    if (prev_swear and not curr_swear):\n",
    "        # swear word removed\n",
    "        return 2\n",
    "    if (prev_swear and  curr_swear):\n",
    "        # swear word in both\n",
    "        return 3\n",
    "    if (not prev_swear and not curr_swear):\n",
    "        # swear word in none\n",
    "        return 0\n",
    "\n",
    "def swear_check_pandas(row, words_dict, lowercase=True):\n",
    "    return swear_check(row[\"currentValue\"], row[\"previousValue\"], words_dict, lowercase=lowercase)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "import numpy as np\n",
    "\n",
    "def timedelta_to_seconds(arr): return arr.total_seconds()\n",
    "def timedelta_to_hours(arr): return arr.total_seconds()/60/60\n",
    "def timedelta_to_days(arr): return arr.total_seconds()/60/60/24\n",
    "def timedelta_to_days_int(arr): return arr.days\n",
    "\n",
    "timedelta_to_seconds = np.vectorize(timedelta_to_seconds)\n",
    "timedelta_to_hours = np.vectorize(timedelta_to_hours)\n",
    "timedelta_to_days = np.vectorize(timedelta_to_days)\n",
    "timedelta_to_days_int = np.vectorize(timedelta_to_days_int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "input_data = Path.home()/\"output-infobox\"\n",
    "inp = list(input_data.rglob('*.json'))\n",
    "files = [x for x in inp if x.is_file()]\n",
    "print(\"number of files:\", len(files))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of files: 586\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# english words dict\n",
    "my_file = open(\"../../../words_alpha.txt\", \"r\")\n",
    "words_dict=set(my_file.read().split(\"\\n\"))\n",
    "\n",
    "# swear words dict\n",
    "swear_file = open(\"../../../words_swear.txt\", \"r\")\n",
    "swear_dict = set(swear_file.read().split(\"\\n\"))\n",
    "swear_dict.remove(\"nazi\") # nazi is mostly no swear word in the context"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "number_of_files = 3\n",
    "num_edits = 0\n",
    "num_change_tuples = 0\n",
    "timedeltas_all = []\n",
    "timedeltas_typo = []\n",
    "timedeltas_levensh = []\n",
    "timedeltas_swear_added = []\n",
    "timedeltas_swear_removed = []\n",
    "for file in tqdm(files[:number_of_files]):\n",
    "    change_tuples = []\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for jsonObj in f:\n",
    "            single_edit = json.loads(jsonObj)\n",
    "            num_edits += 1\n",
    "            title = single_edit['pageTitle']\n",
    "            pageID = single_edit['pageID']\n",
    "            key = single_edit['key']\n",
    "            template = single_edit['template'] if 'template' in single_edit.keys(\n",
    "            ) else None\n",
    "            changes = single_edit['changes']\n",
    "            validFrom = single_edit['validFrom']\n",
    "            revisionId = single_edit['revisionId']\n",
    "            attributes = single_edit['attributes'] if 'attributes' in single_edit.keys(\n",
    "            ) else None\n",
    "            user_name = single_edit['user']['username'] if 'username' in single_edit['user'].keys(\n",
    "            ) else None\n",
    "            user_id = single_edit['user']['id'] if 'id' in single_edit['user'].keys(\n",
    "            ) else None\n",
    "            user_ip = single_edit['user']['ip'] if 'ip' in single_edit['user'].keys(\n",
    "            ) else None\n",
    "            for change in changes:\n",
    "                name = change['property']['name']\n",
    "                current_value = change['currentValue'] if 'currentValue' in change.keys(\n",
    "                ) else None\n",
    "                previous_value = change['previousValue'] if 'previousValue' in change.keys(\n",
    "                ) else None\n",
    "                validTo = change['valueValidTo'] if 'valueValidTo' in change.keys(\n",
    "                ) else None\n",
    "                change_tuples.append((title, pageID, key, template, name, previous_value,\n",
    "                                      current_value, validFrom, validTo, revisionId, user_name, user_id, user_ip, attributes))\n",
    "\n",
    "    data = pd.DataFrame(change_tuples, columns=['pageTitle', 'pageID', 'key', 'template', 'name', 'previousValue',\n",
    "                                                'currentValue', 'validFrom', 'validTo', 'revisionId', 'user_name', 'user_id', 'user_ip', 'attributes'])\n",
    "    num_change_tuples += len(data)\n",
    "    data = data[(data[\"currentValue\"] != \"\") & (~data[\"currentValue\"].isnull())]\n",
    "    data = data[(data[\"previousValue\"] != \"\") & (~data[\"previousValue\"].isnull())]\n",
    "    data = data[(data[\"validTo\"] != \"\") & (~data[\"validTo\"].isnull())]\n",
    "\n",
    "    data['validFrom'] = pd.to_datetime(data['validFrom'])\n",
    "    data['validTo'] = pd.to_datetime(data['validTo'])\n",
    "\n",
    "    timedeltas_all.extend(data[\"validTo\"]-data['validFrom'])\n",
    "\n",
    "    data[\"isTypo\"] = data.apply(lambda row: typo_check_pandas(\n",
    "        row, words_dict, upper_lev_distance=2, skip_no_alpha=True), axis=1)\n",
    "\n",
    "    timedeltas_typo.extend(data[data[\"isTypo\"] == True]\n",
    "                           [\"validTo\"]-data[data[\"isTypo\"] == True]['validFrom'])\n",
    "    timedeltas_levensh.extend(data[~data[\"isTypo\"].isnull()]\n",
    "                              [\"validTo\"]-data[~data[\"isTypo\"].isnull()]['validFrom'])\n",
    "\n",
    "    data[\"swear\"] = data.apply(lambda row: swear_check_pandas(row, swear_dict), axis=1)\n",
    "    timedeltas_swear_added.extend(\n",
    "        data[data[\"swear\"] == 1][\"validTo\"]-data[data[\"swear\"] == 1]['validFrom'])\n",
    "    timedeltas_swear_removed.extend(\n",
    "        data[data[\"swear\"] == 2][\"validTo\"]-data[data[\"swear\"] == 2]['validFrom'])\n",
    "\n",
    "\n",
    "print(\"Read data:\")\n",
    "print(\"Number of edits:\", num_edits)\n",
    "print(\"Number of change tuples:\", num_change_tuples)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3/3 [01:34<00:00, 31.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Read data:\n",
      "Number of edits: 385243\n",
      "Number of change tuples: 1592034\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "print(\"data\")\n",
    "print(\"number of all changes:\", num_change_tuples)\n",
    "print(\"number of all updates:\", len(timedeltas_all))\n",
    "print(\"percent of updates:\", len(timedeltas_all)/num_change_tuples*100)\n",
    "print(\"\\nmatching levenshtein dist of 2\")\n",
    "print(\"number of matching levenshtein dist of 2:\", len(timedeltas_levensh))\n",
    "print(\"percent of updates matching levenshtein dist of 2:\", len(timedeltas_levensh)/len(timedeltas_all)*100)\n",
    "print(\"typos\")\n",
    "print(\"\\nnumber of fixed typos:\", len(timedeltas_typo))\n",
    "print(\"percent of updates with typo:\", len(timedeltas_typo)/len(timedeltas_all)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data\n",
      "number of all changes: 1592034\n",
      "number of all updates: 338112\n",
      "percent of updates: 21.237737385005598\n",
      "\n",
      "matching levenshtein dist of 2\n",
      "number of matching levenshtein dist of 2: 22702\n",
      "percent of updates matching levenshtein dist of 2: 6.714343176225629\n",
      "typos\n",
      "\n",
      "number of fixed typos: 8393\n",
      "percent of updates with typo: 2.4823135529055462\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time to Change"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "print(\"ALL UPDATES\")\n",
    "print(\"median of timedelta of in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_all)))\n",
    "print(\"mean timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_all).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_all).std())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ALL UPDATES\n",
      "median of timedelta of in days: 41.953298611111116\n",
      "mean timedelta of in days: 335.78714151870184\n",
      "std of timedelta of in days: 633.6958786241099\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "print(\"LEVENSHTEIN OF 2\")\n",
    "print(\"median of timedelta in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_levensh)))\n",
    "print(\"mean timedelta in days:\",\n",
    "      timedelta_to_days(timedeltas_levensh).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_levensh).std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEVENSHTEIN OF 2\n",
      "median of timedelta in days: 110.05748842592592\n",
      "mean timedelta in days: 430.66782296418245\n",
      "std of timedelta of in days: 701.3017121699444\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "print(\"TYPOS\")\n",
    "print(\"median of timedelta in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_typo)))\n",
    "print(\"mean timedelta in days:\",\n",
    "      timedelta_to_days(timedeltas_typo).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_typo).std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TYPOS\n",
      "median of timedelta in days: 142.15240740740742\n",
      "mean timedelta in days: 479.8548766277895\n",
      "std of timedelta of in days: 752.7216704589307\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "data[data[\"isTypo\"]==True]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          pageTitle   pageID          key  \\\n",
       "177                                     Nelson Cruz  6159471  149830852-0   \n",
       "181                                     Nelson Cruz  6159471  149830852-0   \n",
       "228                                     Nelson Cruz  6159471  149830852-0   \n",
       "406                                     Nelson Cruz  6159471  149830852-0   \n",
       "438                                     Nelson Cruz  6159471  149830852-0   \n",
       "...                                             ...      ...          ...   \n",
       "560049                  Sunrise over a Sea of Blood  6135665   66094180-0   \n",
       "560229                              Ciaran Donnelly  6174068   75276638-0   \n",
       "560531  Sideshow (The Adventures of Batman & Robin)  6188523   66733552-0   \n",
       "560736                                 Castellabate  6125780  101811542-0   \n",
       "561357                                    Konistres  6162857  308710087-0   \n",
       "\n",
       "                            template              name  \\\n",
       "177               infobox mlb player        stat1label   \n",
       "181               infobox mlb player          position   \n",
       "228               infobox mlb player          position   \n",
       "406               infobox mlb player          position   \n",
       "438               infobox mlb player              bats   \n",
       "...                              ...               ...   \n",
       "560049                 infobox album           reviews   \n",
       "560229  infobox football biography 2       dateofbirth   \n",
       "560531    infobox television episode              next   \n",
       "560736                infobox cityit  population_as_of   \n",
       "561357           infobox greek dimos            periph   \n",
       "\n",
       "                                            previousValue  \\\n",
       "177                                   [[Batting Average]]   \n",
       "181                                         Right Fielder   \n",
       "228                                     [[Right fielder]]   \n",
       "406                                     [[Right Fielder]]   \n",
       "438                                                 right   \n",
       "...                                                   ...   \n",
       "560049  * [[Jesus Freak Hideout]] {{rating-5|3.5}} <re...   \n",
       "560229             {{birth date and age|1984|4|2|df=yes}}   \n",
       "560531                           [[A Bullet For Bullock]]   \n",
       "560736                          [[december 31]], [[2004]]   \n",
       "561357      [[Central Greece (periphery)|Central Greece]]   \n",
       "\n",
       "                                             currentValue  \\\n",
       "177                                   [[Batting average]]   \n",
       "181                                         Right fielder   \n",
       "228                                     [[Right Fielder]]   \n",
       "406                                     [[Right fielder]]   \n",
       "438                                                 Right   \n",
       "...                                                   ...   \n",
       "560049  * [[Jesus Freak Hideout]] {{Rating|3.5|5}} <re...   \n",
       "560229             {{Birth date and age|1984|4|2|df=yes}}   \n",
       "560531                           [[A Bullet for Bullock]]   \n",
       "560736                                  December 31, 2004   \n",
       "561357        [[Central Greece Periphery|Central Greece]]   \n",
       "\n",
       "                       validFrom                   validTo  revisionId  \\\n",
       "177    2008-10-04 05:01:13+00:00 2015-02-11 02:57:35+00:00   242905092   \n",
       "181    2008-10-04 05:01:13+00:00 2009-01-17 02:17:35+00:00   242905092   \n",
       "228    2010-03-30 23:17:01+00:00 2013-05-17 17:18:08+00:00   353050611   \n",
       "406    2013-05-17 17:18:08+00:00 2013-06-04 23:21:54+00:00   555539361   \n",
       "438    2013-09-21 02:19:49+00:00 2015-02-11 02:57:35+00:00   573859300   \n",
       "...                          ...                       ...         ...   \n",
       "560049 2008-09-21 02:21:00+00:00 2012-10-04 18:39:10+00:00   239914276   \n",
       "560229 2010-09-24 04:22:40+00:00 2012-11-26 21:51:34+00:00   386682567   \n",
       "560531 2007-03-11 22:08:59+00:00 2007-08-14 22:33:45+00:00   114394184   \n",
       "560736 2009-09-20 19:42:22+00:00 2011-10-08 12:21:48+00:00   315150259   \n",
       "561357 2011-04-10 20:20:03+00:00 2011-11-20 20:34:00+00:00   423393978   \n",
       "\n",
       "              user_name     user_id       user_ip  \\\n",
       "177             Jackal4   1776444.0          None   \n",
       "181             Jackal4   1776444.0          None   \n",
       "228                None         NaN  24.208.75.32   \n",
       "406     Trut-h-urts man   8334148.0          None   \n",
       "438                None         NaN  69.117.59.46   \n",
       "...                 ...         ...           ...   \n",
       "560049         DinoBot2   7128788.0          None   \n",
       "560229  Rich Farmbrough     82835.0          None   \n",
       "560531           Mellum     45569.0          None   \n",
       "560736     Plasticspork  10068830.0          None   \n",
       "561357        Markussep     96340.0          None   \n",
       "\n",
       "                                               attributes isTypo  swear  \n",
       "177     {'stat2label': '[[Home run]]s', 'image': 'Repl...   True      0  \n",
       "181     {'stat2label': '[[Home run]]s', 'image': 'Repl...   True      0  \n",
       "228     {'stat2label': '[[Home run]]s', 'image': '0007...   True      0  \n",
       "406     {'stat2label': '[[Hit (baseball)|Hit]]s', 'ima...   True      0  \n",
       "438     {'stat2label': '[[Hit (baseball)|Hit]]s', 'ima...   True      0  \n",
       "...                                                   ...    ...    ...  \n",
       "560049  {'cover': 'SOASOB_Better.jpg', 'reviews': '* [...   True      0  \n",
       "560229  {'cityofbirth': '[[Blackpool]]', 'youthclubs1'...   True      0  \n",
       "560531  {'next': '[[A Bullet for Bullock]]', 'image': ...   True      0  \n",
       "560736  {'official_name': 'Comune di Castellabate', 'p...   True      0  \n",
       "561357  {'area_municunit': '127.6', 'city_seal': '', '...   True      0  \n",
       "\n",
       "[3150 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pageTitle</th>\n",
       "      <th>pageID</th>\n",
       "      <th>key</th>\n",
       "      <th>template</th>\n",
       "      <th>name</th>\n",
       "      <th>previousValue</th>\n",
       "      <th>currentValue</th>\n",
       "      <th>validFrom</th>\n",
       "      <th>validTo</th>\n",
       "      <th>revisionId</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>attributes</th>\n",
       "      <th>isTypo</th>\n",
       "      <th>swear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>stat1label</td>\n",
       "      <td>[[Batting Average]]</td>\n",
       "      <td>[[Batting average]]</td>\n",
       "      <td>2008-10-04 05:01:13+00:00</td>\n",
       "      <td>2015-02-11 02:57:35+00:00</td>\n",
       "      <td>242905092</td>\n",
       "      <td>Jackal4</td>\n",
       "      <td>1776444.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'stat2label': '[[Home run]]s', 'image': 'Repl...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>position</td>\n",
       "      <td>Right Fielder</td>\n",
       "      <td>Right fielder</td>\n",
       "      <td>2008-10-04 05:01:13+00:00</td>\n",
       "      <td>2009-01-17 02:17:35+00:00</td>\n",
       "      <td>242905092</td>\n",
       "      <td>Jackal4</td>\n",
       "      <td>1776444.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'stat2label': '[[Home run]]s', 'image': 'Repl...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>position</td>\n",
       "      <td>[[Right fielder]]</td>\n",
       "      <td>[[Right Fielder]]</td>\n",
       "      <td>2010-03-30 23:17:01+00:00</td>\n",
       "      <td>2013-05-17 17:18:08+00:00</td>\n",
       "      <td>353050611</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.208.75.32</td>\n",
       "      <td>{'stat2label': '[[Home run]]s', 'image': '0007...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>position</td>\n",
       "      <td>[[Right Fielder]]</td>\n",
       "      <td>[[Right fielder]]</td>\n",
       "      <td>2013-05-17 17:18:08+00:00</td>\n",
       "      <td>2013-06-04 23:21:54+00:00</td>\n",
       "      <td>555539361</td>\n",
       "      <td>Trut-h-urts man</td>\n",
       "      <td>8334148.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'stat2label': '[[Hit (baseball)|Hit]]s', 'ima...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>bats</td>\n",
       "      <td>right</td>\n",
       "      <td>Right</td>\n",
       "      <td>2013-09-21 02:19:49+00:00</td>\n",
       "      <td>2015-02-11 02:57:35+00:00</td>\n",
       "      <td>573859300</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.117.59.46</td>\n",
       "      <td>{'stat2label': '[[Hit (baseball)|Hit]]s', 'ima...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560049</th>\n",
       "      <td>Sunrise over a Sea of Blood</td>\n",
       "      <td>6135665</td>\n",
       "      <td>66094180-0</td>\n",
       "      <td>infobox album</td>\n",
       "      <td>reviews</td>\n",
       "      <td>* [[Jesus Freak Hideout]] {{rating-5|3.5}} &lt;re...</td>\n",
       "      <td>* [[Jesus Freak Hideout]] {{Rating|3.5|5}} &lt;re...</td>\n",
       "      <td>2008-09-21 02:21:00+00:00</td>\n",
       "      <td>2012-10-04 18:39:10+00:00</td>\n",
       "      <td>239914276</td>\n",
       "      <td>DinoBot2</td>\n",
       "      <td>7128788.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cover': 'SOASOB_Better.jpg', 'reviews': '* [...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560229</th>\n",
       "      <td>Ciaran Donnelly</td>\n",
       "      <td>6174068</td>\n",
       "      <td>75276638-0</td>\n",
       "      <td>infobox football biography 2</td>\n",
       "      <td>dateofbirth</td>\n",
       "      <td>{{birth date and age|1984|4|2|df=yes}}</td>\n",
       "      <td>{{Birth date and age|1984|4|2|df=yes}}</td>\n",
       "      <td>2010-09-24 04:22:40+00:00</td>\n",
       "      <td>2012-11-26 21:51:34+00:00</td>\n",
       "      <td>386682567</td>\n",
       "      <td>Rich Farmbrough</td>\n",
       "      <td>82835.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cityofbirth': '[[Blackpool]]', 'youthclubs1'...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560531</th>\n",
       "      <td>Sideshow (The Adventures of Batman &amp; Robin)</td>\n",
       "      <td>6188523</td>\n",
       "      <td>66733552-0</td>\n",
       "      <td>infobox television episode</td>\n",
       "      <td>next</td>\n",
       "      <td>[[A Bullet For Bullock]]</td>\n",
       "      <td>[[A Bullet for Bullock]]</td>\n",
       "      <td>2007-03-11 22:08:59+00:00</td>\n",
       "      <td>2007-08-14 22:33:45+00:00</td>\n",
       "      <td>114394184</td>\n",
       "      <td>Mellum</td>\n",
       "      <td>45569.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'next': '[[A Bullet for Bullock]]', 'image': ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560736</th>\n",
       "      <td>Castellabate</td>\n",
       "      <td>6125780</td>\n",
       "      <td>101811542-0</td>\n",
       "      <td>infobox cityit</td>\n",
       "      <td>population_as_of</td>\n",
       "      <td>[[december 31]], [[2004]]</td>\n",
       "      <td>December 31, 2004</td>\n",
       "      <td>2009-09-20 19:42:22+00:00</td>\n",
       "      <td>2011-10-08 12:21:48+00:00</td>\n",
       "      <td>315150259</td>\n",
       "      <td>Plasticspork</td>\n",
       "      <td>10068830.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'official_name': 'Comune di Castellabate', 'p...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561357</th>\n",
       "      <td>Konistres</td>\n",
       "      <td>6162857</td>\n",
       "      <td>308710087-0</td>\n",
       "      <td>infobox greek dimos</td>\n",
       "      <td>periph</td>\n",
       "      <td>[[Central Greece (periphery)|Central Greece]]</td>\n",
       "      <td>[[Central Greece Periphery|Central Greece]]</td>\n",
       "      <td>2011-04-10 20:20:03+00:00</td>\n",
       "      <td>2011-11-20 20:34:00+00:00</td>\n",
       "      <td>423393978</td>\n",
       "      <td>Markussep</td>\n",
       "      <td>96340.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'area_municunit': '127.6', 'city_seal': '', '...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3150 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Swear words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def check_swear(str1, str2, words_dict, lowercase=True):\n",
    "    \"\"\" Check if swear got added or removed.\n",
    "        Input:\n",
    "            str1: prev string\n",
    "            str2: curr string\n",
    "        Output:\n",
    "        prev false , curr true : 1 (swear word added)\n",
    "        prev true , curr false : 2 (swear word removed)\n",
    "    \"\"\"\n",
    "    if lowercase:\n",
    "        str1=str1.lower()\n",
    "        str2=str2.lower()\n",
    "\n",
    "    str1_lst=str1.split()\n",
    "    str2_lst=str2.split()\n",
    "\n",
    "    prev_swear=False\n",
    "    curr_swear=False\n",
    "    for string in str1_lst:\n",
    "        if word_in_dict(string, words_dict):\n",
    "            prev_swear=True\n",
    "            break\n",
    "\n",
    "    for string in str2_lst:\n",
    "        if word_in_dict(string, words_dict):\n",
    "            curr_swear=True\n",
    "            break\n",
    "\n",
    "    if (not prev_swear and curr_swear):\n",
    "        # swear word added\n",
    "        return 1\n",
    "    if (prev_swear and not curr_swear):\n",
    "        # swear word removed\n",
    "        return 2\n",
    "    if (prev_swear and  curr_swear):\n",
    "        # swear word in both\n",
    "        return 3\n",
    "    if (not prev_swear and not curr_swear):\n",
    "        # swear word in none\n",
    "        return 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "swear_file = open(\"../../../words_swear.txt\", \"r\")\n",
    "swear_dict = set(swear_file.read().split(\"\\n\"))\n",
    "swear_dict.remove(\"nazi\") # nazi is mostly no swear word in the context\n",
    "\n",
    "def is_not_empty_or_none(input):\n",
    "    return input is not None and input is not \"\"\n",
    "\n",
    "\n",
    "swear_lst = []\n",
    "for i in tqdm(range(len(change_tuples))):\n",
    "    if(is_not_empty_or_none(change_tuples[i][5]) and is_not_empty_or_none(change_tuples[i][6])):\n",
    "        swear_lst.append(check_swear(\n",
    "            change_tuples[i][5], change_tuples[i][6], swear_dict))\n",
    "    else:\n",
    "        swear_lst.append(None)\n",
    "\n",
    "\n",
    "counts_swear = {\"Swearwords added\": 0,\n",
    "                \"Swearwords removed\": 0,\n",
    "                \"Swearwords not touched\": 0,\n",
    "                \"Swearwords not found\": 0,\n",
    "                \"create or delete (skipped)\": 0}\n",
    "for test in swear_lst:\n",
    "    if test is 1:\n",
    "        counts_swear[\"Swearwords added\"] += 1\n",
    "    if test is 2:\n",
    "        counts_swear[\"Swearwords removed\"] += 1\n",
    "    if test is 3:\n",
    "        counts_swear[\"Swearwords not touched\"] += 1\n",
    "    if test is 0:\n",
    "        counts_swear[\"Swearwords not found\"] += 1\n",
    "    if test is None:\n",
    "        # prev or curr is None\n",
    "        counts_swear[\"create or delete (skipped)\"] += 1\n",
    "print(counts_swear)\n",
    "\n",
    "idx_swear = [[], []]\n",
    "for i in range(len(swear_lst)):\n",
    "    if swear_lst[i] == 1:\n",
    "        idx_swear[0].append(i)\n",
    "    if swear_lst[i] == 2:\n",
    "        idx_swear[1].append(i)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Swearwords added:\", counts_swear[\"Swearwords added\"])\n",
    "print(\"Swearwords removed:\", counts_swear[\"Swearwords removed\"])\n",
    "print(\"Swearwords not touched:\", counts_swear[\"Swearwords not touched\"])\n",
    "print(\"Swearwords not found:\", counts_swear[\"Swearwords not found\"])\n",
    "print(\"create or delete (skipped):\", counts_swear[\"create or delete (skipped)\"])\n",
    "edit_count = counts_swear[\"Swearwords added\"]+counts_swear[\"Swearwords removed\"] + \\\n",
    "    counts_swear[\"Swearwords not touched\"]+counts_swear[\"Swearwords not found\"]\n",
    "print(\"Toal tuples (only updates without creations/deletions):\", edit_count)\n",
    "print(\"Toal tuples:\", edit_count+counts_swear[\"create or delete (skipped)\"])\n",
    "print(\"Percentage of swear words in edits (only updates without creations/deletions) added and removed:\",\n",
    "      counts_swear[\"Swearwords added\"]/edit_count, counts_swear[\"Swearwords removed\"]/edit_count)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Swear words added"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_deltas_swear = timedeltas_between_changes(idx_swear[0], change_tuples)\n",
    "time_deltas_swear = np.array(time_deltas_swear)\n",
    "print(\"Average Time to change for a typofix\")\n",
    "print(\"Median time in days\", np.median(timedelta_to_days(time_deltas_swear)))\n",
    "print(\"Median time in hours\", np.median(timedelta_to_hours(time_deltas_swear)))\n",
    "print(\"Median time in seconds\", np.median(timedelta_to_seconds(time_deltas_swear)))\n",
    "print(\"timedelta mean and std in days:\", np.mean(\n",
    "    timedelta_to_days(time_deltas_swear)), np.std(timedelta_to_days(time_deltas_swear)))\n",
    "print(\"timedelta mean:\", str(time_deltas_swear.mean()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def removeOutliers(data, percentile):\n",
    "    lower_quartile = np.percentile(data, percentile)\n",
    "    upper_quartile = np.percentile(data, 100-percentile)\n",
    "    if lower_quartile == upper_quartile:\n",
    "        return data\n",
    "    print(lower_quartile, upper_quartile)\n",
    "    data = data[data >= lower_quartile]\n",
    "    data = data[data < upper_quartile]\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.iloc[idx_swear[0]].head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Swear words removed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.iloc[idx_swear[1]].head(10)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('mp': conda)"
  },
  "interpreter": {
   "hash": "9d6890af0e7111529245105513a4571ecfc3e378a026bfe7b711a2eb3eb8eca5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}