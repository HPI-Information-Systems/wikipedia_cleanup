{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import matplotlib.pyplot as plt\n",
    "import fastDamerauLevenshtein"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How does it work\n",
    "Typos:\n",
    "- previous and current values are splittet into words with non letters/whitespaces removed, if any are None or empty they are skipped\n",
    "- only same wordcounts are tested (it is expected that words stay in the same order)\n",
    "- words are compared to the words with the same index with Damerau-Levenshtein edit distance (swaps are cost 1 not 2)\n",
    "- if any word has edit distance 1 or 2 it is further looked at\n",
    "    1. test if first letter is a case swap (it is expected the user knows what is correct)\n",
    "    2. test if previous word is not in a dictionary but current word is (comparison is done in lowercase)\n",
    "- if any of the tests is true the change is marked as typo-fix\n",
    "\n",
    "Swear words:\n",
    "- previous and current values are splittet into words, if any are None or empty they are skipped\n",
    "- words are compared to a swear word dictionary (https://github.com/RobertJGabriel/Google-profanity-words/blob/master/list.txt)\n",
    "- if any word is matched the value is flagged as swear word\n",
    "- if previous value has no swear word but current value has -> swear word added\n",
    "- if previous value has a swear word but current value has not -> swear word deleted"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# splits string in words\n",
    "def split_strings(str1, str2):\n",
    "    lst = [str1.split()]\n",
    "    lst.append(str2.split())\n",
    "    return lst\n",
    "\n",
    "# checks if wordcount in both strings is equal\n",
    "\n",
    "\n",
    "def same_wordcounts(lst1, lst2):\n",
    "    return (len(lst1) == len(lst2))\n",
    "\n",
    "# deletes non alphabetical characters from string\n",
    "\n",
    "\n",
    "def skip_no_alpha(string):\n",
    "    only_alpha = \"\"\n",
    "    for char in string:\n",
    "        if char.isalpha() or char == \" \":\n",
    "            only_alpha += char\n",
    "    return only_alpha\n",
    "\n",
    "# checks in numbers are increments\n",
    "\n",
    "\n",
    "def is_increment(nr1, nr2):\n",
    "    return (nr1+1 == nr2 or nr1-1 == nr2)\n",
    "\n",
    "# checks if case (upper/loewr) of the first latter is switched\n",
    "\n",
    "\n",
    "def is_first_letter_caseswitch(str1, str2):\n",
    "    return (str1[0].isupper() and str2[0].islower() or str1[0].islower() and str2[0].isupper())\n",
    "\n",
    "\n",
    "def is_not_empty_or_none(input):\n",
    "    return input is not None and input is not \"\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_levenshtein_dists(lst1, lst2):\n",
    "    if len(lst1) != len(lst2):\n",
    "        print(\"Difference words counts of lists!\")\n",
    "        return\n",
    "    dists = []\n",
    "    for i in range(len(lst1)):\n",
    "            dists.append(int(fastDamerauLevenshtein.damerauLevenshtein(\n",
    "                lst1[i], lst2[i], similarity=False)))\n",
    "    return dists\n",
    "\n",
    "# splits strings in words\n",
    "def get_words_and_dists(str1, str2, only_alpha=False):\n",
    "    if only_alpha:\n",
    "        str1=skip_no_alpha(str1)\n",
    "        str2=skip_no_alpha(str2)\n",
    "    words = split_strings(str1, str2)\n",
    "    if len(words[0]) == len(words[1]):\n",
    "        dists = get_levenshtein_dists(words[0], words[1])\n",
    "    else:\n",
    "        dists = []\n",
    "    return words, dists\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "all_words_in_dict(\"horse is \",words_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "def word_in_dict(str1, words_dict):\n",
    "    return str1 in words_dict\n",
    "\n",
    "\n",
    "def all_words_in_dict(str1, words_dict):\n",
    "    lst = skip_no_alpha(str1).lower().split()\n",
    "    for string in lst:\n",
    "        if(not word_in_dict(string,words_dict)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def no_words_in_dict(str1, words_dict):\n",
    "    lst = str1.lower().split()\n",
    "    for string in lst:\n",
    "        if(word_in_dict(string,words_dict)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_typo_fixed(str1, str2, words_dict, lowercase=True):\n",
    "    \"\"\" Check if typo is fixed.\n",
    "        return 0: no other case is found\n",
    "        return 1: word was not in dict before (missspelled)\n",
    "        return 2: word with swapped first letter (and other changes depending on edit distance)\n",
    "    \"\"\"\n",
    "    # detects number errors (dreher,tippfehler), skipps increments. Only works if skip_no_alpha is false\n",
    "    if str1.isdigit() and str2.isdigit() and not is_increment(int(str1), int(str2)):\n",
    "        return 3\n",
    "\n",
    "    if is_first_letter_caseswitch(str1, str2):\n",
    "        return 2\n",
    "\n",
    "    if lowercase:\n",
    "        str1 = str1.lower()\n",
    "        str2 = str2.lower()\n",
    "\n",
    "    # checks if str1 is not in dict but str2 is\n",
    "    if (not word_in_dict(str1, words_dict) and word_in_dict(str2, words_dict)):\n",
    "        return 1\n",
    "\n",
    "    return 0\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_typo_type(str1, str2, words_dict, upper_lev_distance=2, skip_no_alpha=False):\n",
    "    words, levenshtein_dists = get_words_and_dists(\n",
    "        str1, str2, skip_no_alpha)\n",
    "    typo_lst = []\n",
    "    for i in range(len(levenshtein_dists)):  # only loops if dists are found (word counts are equal)\n",
    "        # only uses distances >0 <=2\n",
    "        if(levenshtein_dists[i] > 0 and levenshtein_dists[i] <= upper_lev_distance):\n",
    "            typo_lst.append(is_typo_fixed(\n",
    "                words[0][i], words[1][i], words_dict))\n",
    "        # else:  # appends None if dist is <0 or >2\n",
    "        #     typo_lst.append(None)\n",
    "    return typo_lst\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "my_file = open(\"../../../words_alpha.txt\", \"r\")\n",
    "words_dict=set(my_file.read().split(\"\\n\"))\n",
    "\n",
    "testcase1 = [\"Hier sind kkeine Fheler\", \"Hier sind keine Fehler\"]\n",
    "testcase1_en = [\"There are nno erorrs\", \"There are no errors\"]\n",
    "typo_lst = get_typo_type(testcase1_en[0], testcase1_en[1], words_dict)\n",
    "print(typo_lst)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def typo_check(str1, str2, words_dict, upper_lev_distance=2, skip_no_alpha=False):\n",
    "    \"\"\"Return True if typo\n",
    "       Return False if no typo\n",
    "    \"\"\"\n",
    "    typo_lst = get_typo_type(str1, str2, words_dict, upper_lev_distance, skip_no_alpha)\n",
    "    if len(typo_lst) == 0:\n",
    "        return None\n",
    "    for typo_type in typo_lst:\n",
    "        if typo_type > 0:  # 1 is previous not in dict, current is in dict, 2 case switch on first letter\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def typo_check_pandas(row, words_dict, upper_lev_distance=2, skip_no_alpha=False):\n",
    "    \"\"\"Return True if typo\n",
    "       Return False if no typo\n",
    "    \"\"\"\n",
    "    typo_lst = get_typo_type(row[\"currentValue\"], row[\"previousValue\"], words_dict, upper_lev_distance, skip_no_alpha)\n",
    "    if len(typo_lst) == 0:\n",
    "        return None\n",
    "    for typo_type in typo_lst:\n",
    "        if typo_type > 0:  # 1 is previous not in dict, current is in dict, 2 case switch on first letter\n",
    "            return True\n",
    "    return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def swear_check(str1, str2, words_dict, lowercase=True):\n",
    "    \"\"\" Check if swear got added or removed.\n",
    "        Input:\n",
    "            str1: prev string\n",
    "            str2: curr string\n",
    "        Output:\n",
    "        prev false , curr true : 1 (swear word added)\n",
    "        prev true , curr false : 2 (swear word removed)\n",
    "    \"\"\"\n",
    "    if lowercase:\n",
    "        str1=str1.lower()\n",
    "        str2=str2.lower()\n",
    "\n",
    "    str1_lst=str1.split()\n",
    "    str2_lst=str2.split()\n",
    "\n",
    "    prev_swear=False\n",
    "    curr_swear=False\n",
    "    for string in str1_lst:\n",
    "        if word_in_dict(string, words_dict):\n",
    "            prev_swear=True\n",
    "            break\n",
    "\n",
    "    for string in str2_lst:\n",
    "        if word_in_dict(string, words_dict):\n",
    "            curr_swear=True\n",
    "            break\n",
    "\n",
    "    if (not prev_swear and curr_swear):\n",
    "        # swear word added\n",
    "        return 1\n",
    "    if (prev_swear and not curr_swear):\n",
    "        # swear word removed\n",
    "        return 2\n",
    "    if (prev_swear and  curr_swear):\n",
    "        # swear word in both\n",
    "        return 3\n",
    "    if (not prev_swear and not curr_swear):\n",
    "        # swear word in none\n",
    "        return 0\n",
    "\n",
    "def swear_check_pandas(row, words_dict, lowercase=True):\n",
    "    return swear_check(row[\"currentValue\"], row[\"previousValue\"], words_dict, lowercase=lowercase)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import numpy as np\n",
    "\n",
    "def timedelta_to_seconds(arr): return arr.total_seconds()\n",
    "def timedelta_to_hours(arr): return arr.total_seconds()/60/60\n",
    "def timedelta_to_days(arr): return arr.total_seconds()/60/60/24\n",
    "def timedelta_to_days_int(arr): return arr.days\n",
    "\n",
    "timedelta_to_seconds = np.vectorize(timedelta_to_seconds)\n",
    "timedelta_to_hours = np.vectorize(timedelta_to_hours)\n",
    "timedelta_to_days = np.vectorize(timedelta_to_days)\n",
    "timedelta_to_days_int = np.vectorize(timedelta_to_days_int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "input_data = Path.home()/\"output-infobox\"\n",
    "inp = list(input_data.rglob('*.json'))\n",
    "files = [x for x in inp if x.is_file()]\n",
    "print(\"number of files:\", len(files))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of files: 586\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# english words dict\n",
    "my_file = open(\"../../../words_alpha.txt\", \"r\")\n",
    "words_dict=set(my_file.read().split(\"\\n\"))\n",
    "\n",
    "# swear words dict\n",
    "swear_file = open(\"../../../words_swear.txt\", \"r\")\n",
    "swear_dict = set(swear_file.read().split(\"\\n\"))\n",
    "swear_dict.remove(\"nazi\") # nazi is mostly no swear word in the context"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "number_of_files = 3\n",
    "num_edits = 0\n",
    "num_change_tuples = 0\n",
    "timedeltas_all = []\n",
    "timedeltas_wordsNotInDict = []\n",
    "timedeltas_swearWordinCurrentValue = []\n",
    "timedeltas_typo = []\n",
    "timedeltas_levensh = []\n",
    "timedeltas_swear_added = []\n",
    "timedeltas_swear_removed = []\n",
    "for file in tqdm(files[:number_of_files]):\n",
    "    change_tuples = []\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for jsonObj in f:\n",
    "            single_edit = json.loads(jsonObj)\n",
    "            num_edits += 1\n",
    "            title = single_edit['pageTitle']\n",
    "            pageID = single_edit['pageID']\n",
    "            key = single_edit['key']\n",
    "            template = single_edit['template'] if 'template' in single_edit.keys(\n",
    "            ) else None\n",
    "            changes = single_edit['changes']\n",
    "            validFrom = single_edit['validFrom']\n",
    "            revisionId = single_edit['revisionId']\n",
    "            attributes = single_edit['attributes'] if 'attributes' in single_edit.keys(\n",
    "            ) else None\n",
    "            user_name = single_edit['user']['username'] if 'username' in single_edit['user'].keys(\n",
    "            ) else None\n",
    "            user_id = single_edit['user']['id'] if 'id' in single_edit['user'].keys(\n",
    "            ) else None\n",
    "            user_ip = single_edit['user']['ip'] if 'ip' in single_edit['user'].keys(\n",
    "            ) else None\n",
    "            for change in changes:\n",
    "                name = change['property']['name']\n",
    "                current_value = change['currentValue'] if 'currentValue' in change.keys(\n",
    "                ) else None\n",
    "                previous_value = change['previousValue'] if 'previousValue' in change.keys(\n",
    "                ) else None\n",
    "                validTo = change['valueValidTo'] if 'valueValidTo' in change.keys(\n",
    "                ) else None\n",
    "                change_tuples.append((title, pageID, key, template, name, previous_value,\n",
    "                                      current_value, validFrom, validTo, revisionId, user_name, user_id, user_ip, attributes))\n",
    "    # data preprocessing\n",
    "    data_raw = pd.DataFrame(change_tuples, columns=['pageTitle', 'pageID', 'key', 'template', 'name', 'previousValue',\n",
    "                                                    'currentValue', 'validFrom', 'validTo', 'revisionId', 'user_name', 'user_id', 'user_ip', 'attributes'])\n",
    "    num_change_tuples += len(data_raw)\n",
    "    data = data_raw[(data_raw[\"currentValue\"] != \"\") &\n",
    "                    (~data_raw[\"currentValue\"].isnull())]\n",
    "    data = data[(data[\"previousValue\"] != \"\") & (~data[\"previousValue\"].isnull())]\n",
    "    data = data[(data[\"validTo\"] != \"\") & (~data[\"validTo\"].isnull())]\n",
    "    data['validFrom'] = pd.to_datetime(data['validFrom'])\n",
    "    data['validTo'] = pd.to_datetime(data['validTo'])\n",
    "    data_raw['validFrom'] = pd.to_datetime(data_raw['validFrom'])\n",
    "    data_raw['validTo'] = pd.to_datetime(data_raw['validTo'])\n",
    "\n",
    "    timedeltas_all.extend(data[\"validTo\"]-data['validFrom'])\n",
    "\n",
    "    data[\"isTypo\"] = data.apply(lambda row: typo_check_pandas(\n",
    "        row, words_dict, upper_lev_distance=2, skip_no_alpha=True), axis=1)\n",
    "\n",
    "    data[\"allWordsInDict\"] = data.apply(\n",
    "        lambda row: all_words_in_dict(row[\"currentValue\"], words_dict), axis=1)\n",
    "    timedeltas_wordsNotInDict.extend(\n",
    "        data[data[\"allWordsInDict\"] == False][\"validTo\"]-data[data[\"allWordsInDict\"] == False]['validFrom'])\n",
    "\n",
    "    data[\"swearWordinCurrentValue\"] = data.apply(\n",
    "        lambda row: no_words_in_dict(row[\"currentValue\"], swear_dict), axis=1)\n",
    "    timedeltas_swearWordinCurrentValue.extend(\n",
    "        data[data[\"swearWordinCurrentValue\"] == True][\"validTo\"]-data[data[\"swearWordinCurrentValue\"] == True]['validFrom'])\n",
    "\n",
    "    # lookup for change where typo was inserted (very slow)\n",
    "    # for i, change in data[data[\"isTypo\"] == True].iterrows():\n",
    "    #     change_with_typo = data_raw[\n",
    "    #         (data_raw[\"key\"] == data.loc[i][\"key\"])\n",
    "    #         & (data_raw[\"template\"] == data.loc[i][\"template\"])\n",
    "    #         & (data_raw[\"currentValue\"] == data.loc[i][\"previousValue\"])\n",
    "    #         & (data_raw[\"validTo\"] <= data.loc[i][\"validFrom\"])\n",
    "    #     ].sort_values(\"validTo\", ascending=False).iloc[0]\n",
    "    #     timedeltas_typo=data.loc[i][\"validFrom\"] - change_with_typo[\"validFrom\"]\n",
    "\n",
    "    # timedeltas_typo.extend(data[data[\"isTypo\"] == True]\n",
    "    #                        [\"validTo\"]-data[data[\"isTypo\"] == True]['validFrom'])\n",
    "    # timedeltas_levensh.extend(data[~data[\"isTypo\"].isnull()]\n",
    "    #                           [\"validTo\"]-data[~data[\"isTypo\"].isnull()]['validFrom'])\n",
    "\n",
    "    # data[\"swear\"] = data.apply(lambda row: swear_check_pandas(row, swear_dict), axis=1)\n",
    "    # timedeltas_swear_added.extend(\n",
    "    #     data[data[\"swear\"] == 1][\"validTo\"]-data[data[\"swear\"] == 1]['validFrom'])\n",
    "    # timedeltas_swear_removed.extend(\n",
    "    #     data[data[\"swear\"] == 2][\"validTo\"]-data[data[\"swear\"] == 2]['validFrom'])\n",
    "\n",
    "print(\"Read data:\")\n",
    "print(\"Number of edits:\", num_edits)\n",
    "print(\"Number of change tuples:\", num_change_tuples)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3/3 [00:55<00:00, 18.44s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Read data:\n",
      "Number of edits: 385243\n",
      "Number of change tuples: 1592034\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# data_raw.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# i=141\n",
    "# print(data.loc[i])\n",
    "# change_with_typo=data_raw[\n",
    "#     (data_raw[\"key\"]==data.loc[i][\"key\"])\n",
    "#     & (data_raw[\"template\"]==data.loc[i][\"template\"])\n",
    "#     & (data_raw[\"currentValue\"]==data.loc[i][\"previousValue\"])\n",
    "#     & (data_raw[\"validTo\"]<=data.loc[i][\"validFrom\"])\n",
    "#     ].sort_values(\"validTo\",ascending=False).iloc[0]\n",
    "# print(change_with_typo)\n",
    "# data.loc[i][\"validFrom\"] -change_with_typo[\"validFrom\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# c = 0\n",
    "# # 5 tuple per s\n",
    "# for i, change in tqdm(data[data[\"isTypo\"] == True].iterrows()):\n",
    "#     change_with_typos = data_raw[\n",
    "#         (data_raw[\"key\"] == data.loc[i][\"key\"])\n",
    "#         & (data_raw[\"template\"] == data.loc[i][\"template\"])\n",
    "#         & (data_raw[\"currentValue\"] == data.loc[i][\"previousValue\"])\n",
    "#         & (data_raw[\"validTo\"] <= data.loc[i][\"validFrom\"])\n",
    "#     ].sort_values(\"validTo\", ascending=False)\n",
    "#     if(len(change_with_typos)==0):\n",
    "#         c+=1\n",
    "#     timedeltas_typo=data.loc[i][\"validFrom\"] - change_with_typo[\"validFrom\"]\n",
    "\n",
    "# print(c,len(data[data[\"isTypo\"] == True]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "data[data[\"allWordsInDict\"] == False].head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               pageTitle    pageID          key                     template  \\\n",
       "36   Diamond, California  22598434  288131243-0           infobox settlement   \n",
       "111  Anniyur, Viluppuram  22574055  302200731-0  infobox indian jurisdiction   \n",
       "112  Anniyur, Viluppuram  22574055  302200731-0  infobox indian jurisdiction   \n",
       "113  Anniyur, Viluppuram  22574055  302200731-0  infobox indian jurisdiction   \n",
       "140  Anniyur, Viluppuram  22574055  302200731-0  infobox indian jurisdiction   \n",
       "\n",
       "                    name                previousValue  \\\n",
       "36   elevation_footnotes  <ref>{{gnis|253408}} </ref>   \n",
       "111              website         anniyur.blogspot.com   \n",
       "112          temp_summer                          36c   \n",
       "113          temp_winter                          15c   \n",
       "140           other_name                     Vanniyur   \n",
       "\n",
       "                         currentValue                 validFrom  \\\n",
       "36         <ref>{{gnis|253408}}</ref> 2013-08-03 05:30:35+00:00   \n",
       "111  http://www.anniyur.blogspot.com/ 2010-03-03 13:57:47+00:00   \n",
       "112                   36<sup>0</sup>c 2010-03-03 13:57:47+00:00   \n",
       "113                   15<sup>0</sup>c 2010-03-03 13:57:47+00:00   \n",
       "140                     Thiru Anniyur 2010-04-28 14:55:55+00:00   \n",
       "\n",
       "                      validTo  revisionId     user_name    user_id  \\\n",
       "36  2014-05-11 19:08:20+00:00   566949922        Hmains   508734.0   \n",
       "111 2010-03-03 13:58:03+00:00   347509154  Anniyurkumar  9544593.0   \n",
       "112 2010-03-03 13:58:03+00:00   347509154  Anniyurkumar  9544593.0   \n",
       "113 2010-03-03 13:58:03+00:00   347509154  Anniyurkumar  9544593.0   \n",
       "140 2017-08-03 20:16:50+00:00   358857148          None        NaN   \n",
       "\n",
       "             user_ip                                         attributes  \\\n",
       "36              None  {'lats': '18', 'subdivision_name': '[[United S...   \n",
       "111             None  {'area_total': '', 'altitude': '', 'population...   \n",
       "112             None  {'area_total': '', 'altitude': '', 'population...   \n",
       "113             None  {'area_total': '', 'altitude': '', 'population...   \n",
       "140  117.254.133.108  {'area_total': '', 'altitude': '', 'population...   \n",
       "\n",
       "    isTypo  allWordsInDict  \n",
       "36    None           False  \n",
       "111   None           False  \n",
       "112   None           False  \n",
       "113   None           False  \n",
       "140   None           False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pageTitle</th>\n",
       "      <th>pageID</th>\n",
       "      <th>key</th>\n",
       "      <th>template</th>\n",
       "      <th>name</th>\n",
       "      <th>previousValue</th>\n",
       "      <th>currentValue</th>\n",
       "      <th>validFrom</th>\n",
       "      <th>validTo</th>\n",
       "      <th>revisionId</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>attributes</th>\n",
       "      <th>isTypo</th>\n",
       "      <th>allWordsInDict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Diamond, California</td>\n",
       "      <td>22598434</td>\n",
       "      <td>288131243-0</td>\n",
       "      <td>infobox settlement</td>\n",
       "      <td>elevation_footnotes</td>\n",
       "      <td>&lt;ref&gt;{{gnis|253408}} &lt;/ref&gt;</td>\n",
       "      <td>&lt;ref&gt;{{gnis|253408}}&lt;/ref&gt;</td>\n",
       "      <td>2013-08-03 05:30:35+00:00</td>\n",
       "      <td>2014-05-11 19:08:20+00:00</td>\n",
       "      <td>566949922</td>\n",
       "      <td>Hmains</td>\n",
       "      <td>508734.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'lats': '18', 'subdivision_name': '[[United S...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Anniyur, Viluppuram</td>\n",
       "      <td>22574055</td>\n",
       "      <td>302200731-0</td>\n",
       "      <td>infobox indian jurisdiction</td>\n",
       "      <td>website</td>\n",
       "      <td>anniyur.blogspot.com</td>\n",
       "      <td>http://www.anniyur.blogspot.com/</td>\n",
       "      <td>2010-03-03 13:57:47+00:00</td>\n",
       "      <td>2010-03-03 13:58:03+00:00</td>\n",
       "      <td>347509154</td>\n",
       "      <td>Anniyurkumar</td>\n",
       "      <td>9544593.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'area_total': '', 'altitude': '', 'population...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Anniyur, Viluppuram</td>\n",
       "      <td>22574055</td>\n",
       "      <td>302200731-0</td>\n",
       "      <td>infobox indian jurisdiction</td>\n",
       "      <td>temp_summer</td>\n",
       "      <td>36c</td>\n",
       "      <td>36&lt;sup&gt;0&lt;/sup&gt;c</td>\n",
       "      <td>2010-03-03 13:57:47+00:00</td>\n",
       "      <td>2010-03-03 13:58:03+00:00</td>\n",
       "      <td>347509154</td>\n",
       "      <td>Anniyurkumar</td>\n",
       "      <td>9544593.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'area_total': '', 'altitude': '', 'population...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Anniyur, Viluppuram</td>\n",
       "      <td>22574055</td>\n",
       "      <td>302200731-0</td>\n",
       "      <td>infobox indian jurisdiction</td>\n",
       "      <td>temp_winter</td>\n",
       "      <td>15c</td>\n",
       "      <td>15&lt;sup&gt;0&lt;/sup&gt;c</td>\n",
       "      <td>2010-03-03 13:57:47+00:00</td>\n",
       "      <td>2010-03-03 13:58:03+00:00</td>\n",
       "      <td>347509154</td>\n",
       "      <td>Anniyurkumar</td>\n",
       "      <td>9544593.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'area_total': '', 'altitude': '', 'population...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Anniyur, Viluppuram</td>\n",
       "      <td>22574055</td>\n",
       "      <td>302200731-0</td>\n",
       "      <td>infobox indian jurisdiction</td>\n",
       "      <td>other_name</td>\n",
       "      <td>Vanniyur</td>\n",
       "      <td>Thiru Anniyur</td>\n",
       "      <td>2010-04-28 14:55:55+00:00</td>\n",
       "      <td>2017-08-03 20:16:50+00:00</td>\n",
       "      <td>358857148</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.254.133.108</td>\n",
       "      <td>{'area_total': '', 'altitude': '', 'population...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "print(\"data\")\n",
    "print(\"number of all changes:\", num_change_tuples)\n",
    "print(\"number of all updates:\", len(timedeltas_all))\n",
    "print(\"percent of updates:\", len(timedeltas_all)/num_change_tuples*100)\n",
    "print(\"\\nword not in dict\")\n",
    "print(\"number of updates with word not in dict:\",len(timedeltas_wordsNotInDict))\n",
    "print(\"percent of of updates with word not in dict:\", len(timedeltas_wordsNotInDict)/len(timedeltas_all)*100)\n",
    "\n",
    "print(\"\\nTIMEDELTAS\")\n",
    "print(\"ALL UPDATES\")\n",
    "print(\"median of timedelta of in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_all)))\n",
    "print(\"mean timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_all).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_all).std())\n",
    "print(\"\\nWORDS NOT IN DICT\")\n",
    "print(\"median of timedelta of in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_wordsNotInDict)))\n",
    "print(\"mean timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_wordsNotInDict).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_wordsNotInDict).std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data\n",
      "number of all changes: 604850\n",
      "number of all updates: 109838\n",
      "percent of updates: 18.159543688517815\n",
      "\n",
      "word not in dict\n",
      "number of updates with word not in dict: 62341\n",
      "percent of of updates with word not in dict: 56.75722427575156\n",
      "\n",
      "TIMEDELTAS\n",
      "ALL UPDATES\n",
      "median of timedelta of in days: 29.773449074074072\n",
      "mean timedelta of in days: 316.53805078990916\n",
      "std of timedelta of in days: 605.7614399084337\n",
      "\n",
      "WORDS NOT IN DICT\n",
      "median of timedelta of in days: 34.362627314814816\n",
      "mean timedelta of in days: 342.7451481099398\n",
      "std of timedelta of in days: 635.0877109219608\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "print(\"swear word in current value\")\n",
    "print(\"number of updates with swear word in current value:\",len(timedeltas_swearWordinCurrentValue))\n",
    "print(\"percent of of updates with swear word in current value:\", len(timedeltas_swearWordinCurrentValue)/len(timedeltas_all)*100)\n",
    "\n",
    "print(\"\\nTIMEDELTAS\")\n",
    "print(\"median of timedelta of in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_swearWordinCurrentValue)))\n",
    "print(\"mean timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_swearWordinCurrentValue).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_swearWordinCurrentValue).std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "swear word in current value\n",
      "number of updates with swear word in current value: 1004\n",
      "percent of of updates with swear word in current value: 0.29694302479651713\n",
      "\n",
      "TIMEDELTAS\n",
      "median of timedelta of in days: 0.0014409722222222224\n",
      "mean timedelta of in days: 102.80090351556736\n",
      "std of timedelta of in days: 370.9808194328398\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "data[data[\"swearWordinCurrentValue\"] == True].tail(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                               pageTitle   pageID          key  \\\n",
       "554040                  Jefferson nickel  6174226  423051983-0   \n",
       "554537               Adelaide Raiders SC  6166673   66481663-0   \n",
       "555275  The Anthem (Good Charlotte song)  6163391   66438966-0   \n",
       "556138                       Chad Larson  6176282  174533916-0   \n",
       "560673                    Patrick Carnes  6136554  463019693-0   \n",
       "\n",
       "                      template             name                 previousValue  \\\n",
       "554040            infobox coin     denomination              Jefferson nickel   \n",
       "554537   football club infobox         fullname  Adelaide Raiders Soccer Club   \n",
       "555275          infobox single             name                    The Anthem   \n",
       "556138  infobox musical artist  associated_acts              [[The Aquabats]]   \n",
       "560673          infobox person       occupation                     Counselor   \n",
       "\n",
       "                                 currentValue                 validFrom  \\\n",
       "554040                  Jefferson anus nickel 2013-11-15 19:50:47+00:00   \n",
       "554537        Adelaide fuck heads Soccer Club 2009-05-24 04:29:19+00:00   \n",
       "555275                                The fag 2008-08-04 23:23:32+00:00   \n",
       "556138  [[The Aquabats]], Butt Hole Rebellion 2008-02-06 19:52:10+00:00   \n",
       "560673                  God damn math teacher 2019-05-08 17:01:32+00:00   \n",
       "\n",
       "                         validTo  revisionId      user_name    user_id  \\\n",
       "554040 2013-11-15 20:19:22+00:00   581813462           None        NaN   \n",
       "554537 2009-05-24 04:29:23+00:00   291944361  Ivicajurkovic  9750573.0   \n",
       "555275 2008-08-04 23:23:56+00:00   229875170           None        NaN   \n",
       "556138 2010-12-16 18:35:31+00:00   189564055         Zytsef   509473.0   \n",
       "560673 2019-05-08 17:02:05+00:00   896156126           None        NaN   \n",
       "\n",
       "                user_ip                                         attributes  \\\n",
       "554040  109.145.172.247  {'country': 'United States', 'years of minting...   \n",
       "554537             None  {'body2': 'FFFFFF', 'rightarm2': 'FFFFFF', 'ri...   \n",
       "555275   71.241.184.103  {'artist': '[[Good Charlotte]]', 'chart positi...   \n",
       "556138             None  {'img': '', 'occupation': '[[Musician]]', 'bor...   \n",
       "560673    209.104.242.7  {'agent': 'Stephen Wright', 'education': 'CML ...   \n",
       "\n",
       "       isTypo  allWordsInDict  swearWordinCurrentValue  \n",
       "554040   None            True                     True  \n",
       "554537   None            True                     True  \n",
       "555275   None            True                     True  \n",
       "556138   None           False                     True  \n",
       "560673   None            True                     True  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pageTitle</th>\n",
       "      <th>pageID</th>\n",
       "      <th>key</th>\n",
       "      <th>template</th>\n",
       "      <th>name</th>\n",
       "      <th>previousValue</th>\n",
       "      <th>currentValue</th>\n",
       "      <th>validFrom</th>\n",
       "      <th>validTo</th>\n",
       "      <th>revisionId</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>attributes</th>\n",
       "      <th>isTypo</th>\n",
       "      <th>allWordsInDict</th>\n",
       "      <th>swearWordinCurrentValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554040</th>\n",
       "      <td>Jefferson nickel</td>\n",
       "      <td>6174226</td>\n",
       "      <td>423051983-0</td>\n",
       "      <td>infobox coin</td>\n",
       "      <td>denomination</td>\n",
       "      <td>Jefferson nickel</td>\n",
       "      <td>Jefferson anus nickel</td>\n",
       "      <td>2013-11-15 19:50:47+00:00</td>\n",
       "      <td>2013-11-15 20:19:22+00:00</td>\n",
       "      <td>581813462</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.145.172.247</td>\n",
       "      <td>{'country': 'United States', 'years of minting...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554537</th>\n",
       "      <td>Adelaide Raiders SC</td>\n",
       "      <td>6166673</td>\n",
       "      <td>66481663-0</td>\n",
       "      <td>football club infobox</td>\n",
       "      <td>fullname</td>\n",
       "      <td>Adelaide Raiders Soccer Club</td>\n",
       "      <td>Adelaide fuck heads Soccer Club</td>\n",
       "      <td>2009-05-24 04:29:19+00:00</td>\n",
       "      <td>2009-05-24 04:29:23+00:00</td>\n",
       "      <td>291944361</td>\n",
       "      <td>Ivicajurkovic</td>\n",
       "      <td>9750573.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'body2': 'FFFFFF', 'rightarm2': 'FFFFFF', 'ri...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555275</th>\n",
       "      <td>The Anthem (Good Charlotte song)</td>\n",
       "      <td>6163391</td>\n",
       "      <td>66438966-0</td>\n",
       "      <td>infobox single</td>\n",
       "      <td>name</td>\n",
       "      <td>The Anthem</td>\n",
       "      <td>The fag</td>\n",
       "      <td>2008-08-04 23:23:32+00:00</td>\n",
       "      <td>2008-08-04 23:23:56+00:00</td>\n",
       "      <td>229875170</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.241.184.103</td>\n",
       "      <td>{'artist': '[[Good Charlotte]]', 'chart positi...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556138</th>\n",
       "      <td>Chad Larson</td>\n",
       "      <td>6176282</td>\n",
       "      <td>174533916-0</td>\n",
       "      <td>infobox musical artist</td>\n",
       "      <td>associated_acts</td>\n",
       "      <td>[[The Aquabats]]</td>\n",
       "      <td>[[The Aquabats]], Butt Hole Rebellion</td>\n",
       "      <td>2008-02-06 19:52:10+00:00</td>\n",
       "      <td>2010-12-16 18:35:31+00:00</td>\n",
       "      <td>189564055</td>\n",
       "      <td>Zytsef</td>\n",
       "      <td>509473.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'img': '', 'occupation': '[[Musician]]', 'bor...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560673</th>\n",
       "      <td>Patrick Carnes</td>\n",
       "      <td>6136554</td>\n",
       "      <td>463019693-0</td>\n",
       "      <td>infobox person</td>\n",
       "      <td>occupation</td>\n",
       "      <td>Counselor</td>\n",
       "      <td>God damn math teacher</td>\n",
       "      <td>2019-05-08 17:01:32+00:00</td>\n",
       "      <td>2019-05-08 17:02:05+00:00</td>\n",
       "      <td>896156126</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.104.242.7</td>\n",
       "      <td>{'agent': 'Stephen Wright', 'education': 'CML ...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "print(\"data\")\n",
    "print(\"number of all changes:\", num_change_tuples)\n",
    "print(\"number of all updates:\", len(timedeltas_all))\n",
    "print(\"percent of updates:\", len(timedeltas_all)/num_change_tuples*100)\n",
    "print(\"\\nmatching levenshtein dist of 2\")\n",
    "print(\"number of matching levenshtein dist of 2:\", len(timedeltas_levensh))\n",
    "print(\"percent of updates matching levenshtein dist of 2:\", len(timedeltas_levensh)/len(timedeltas_all)*100)\n",
    "print(\"typos\")\n",
    "print(\"\\nnumber of fixed typos:\", len(timedeltas_typo))\n",
    "print(\"percent of updates with typo:\", len(timedeltas_typo)/len(timedeltas_all)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data\n",
      "number of all changes: 1592034\n",
      "number of all updates: 338112\n",
      "percent of updates: 21.237737385005598\n",
      "\n",
      "matching levenshtein dist of 2\n",
      "number of matching levenshtein dist of 2: 0\n",
      "percent of updates matching levenshtein dist of 2: 0.0\n",
      "typos\n",
      "\n",
      "number of fixed typos: 0\n",
      "percent of updates with typo: 0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time to Change"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "print(\"ALL UPDATES\")\n",
    "print(\"median of timedelta of in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_all)))\n",
    "print(\"mean timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_all).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_all).std())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ALL UPDATES\n",
      "median of timedelta of in days: 41.953298611111116\n",
      "mean timedelta of in days: 335.78714151870184\n",
      "std of timedelta of in days: 633.6958786241099\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "print(\"LEVENSHTEIN OF 2\")\n",
    "print(\"median of timedelta in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_levensh)))\n",
    "print(\"mean timedelta in days:\",\n",
    "      timedelta_to_days(timedeltas_levensh).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_levensh).std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEVENSHTEIN OF 2\n",
      "median of timedelta in days: 110.05748842592592\n",
      "mean timedelta in days: 430.66782296418245\n",
      "std of timedelta of in days: 701.3017121699444\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "print(\"TYPOS\")\n",
    "print(\"median of timedelta in days:\",\n",
    "      np.median(timedelta_to_days(timedeltas_typo)))\n",
    "print(\"mean timedelta in days:\",\n",
    "      timedelta_to_days(timedeltas_typo).mean())\n",
    "print(\"std of timedelta of in days:\",\n",
    "      timedelta_to_days(timedeltas_typo).std())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TYPOS\n",
      "median of timedelta in days: 142.15240740740742\n",
      "mean timedelta in days: 479.8548766277895\n",
      "std of timedelta of in days: 752.7216704589307\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "data[data[\"isTypo\"]==True]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          pageTitle   pageID          key  \\\n",
       "177                                     Nelson Cruz  6159471  149830852-0   \n",
       "181                                     Nelson Cruz  6159471  149830852-0   \n",
       "228                                     Nelson Cruz  6159471  149830852-0   \n",
       "406                                     Nelson Cruz  6159471  149830852-0   \n",
       "438                                     Nelson Cruz  6159471  149830852-0   \n",
       "...                                             ...      ...          ...   \n",
       "560049                  Sunrise over a Sea of Blood  6135665   66094180-0   \n",
       "560229                              Ciaran Donnelly  6174068   75276638-0   \n",
       "560531  Sideshow (The Adventures of Batman & Robin)  6188523   66733552-0   \n",
       "560736                                 Castellabate  6125780  101811542-0   \n",
       "561357                                    Konistres  6162857  308710087-0   \n",
       "\n",
       "                            template              name  \\\n",
       "177               infobox mlb player        stat1label   \n",
       "181               infobox mlb player          position   \n",
       "228               infobox mlb player          position   \n",
       "406               infobox mlb player          position   \n",
       "438               infobox mlb player              bats   \n",
       "...                              ...               ...   \n",
       "560049                 infobox album           reviews   \n",
       "560229  infobox football biography 2       dateofbirth   \n",
       "560531    infobox television episode              next   \n",
       "560736                infobox cityit  population_as_of   \n",
       "561357           infobox greek dimos            periph   \n",
       "\n",
       "                                            previousValue  \\\n",
       "177                                   [[Batting Average]]   \n",
       "181                                         Right Fielder   \n",
       "228                                     [[Right fielder]]   \n",
       "406                                     [[Right Fielder]]   \n",
       "438                                                 right   \n",
       "...                                                   ...   \n",
       "560049  * [[Jesus Freak Hideout]] {{rating-5|3.5}} <re...   \n",
       "560229             {{birth date and age|1984|4|2|df=yes}}   \n",
       "560531                           [[A Bullet For Bullock]]   \n",
       "560736                          [[december 31]], [[2004]]   \n",
       "561357      [[Central Greece (periphery)|Central Greece]]   \n",
       "\n",
       "                                             currentValue  \\\n",
       "177                                   [[Batting average]]   \n",
       "181                                         Right fielder   \n",
       "228                                     [[Right Fielder]]   \n",
       "406                                     [[Right fielder]]   \n",
       "438                                                 Right   \n",
       "...                                                   ...   \n",
       "560049  * [[Jesus Freak Hideout]] {{Rating|3.5|5}} <re...   \n",
       "560229             {{Birth date and age|1984|4|2|df=yes}}   \n",
       "560531                           [[A Bullet for Bullock]]   \n",
       "560736                                  December 31, 2004   \n",
       "561357        [[Central Greece Periphery|Central Greece]]   \n",
       "\n",
       "                       validFrom                   validTo  revisionId  \\\n",
       "177    2008-10-04 05:01:13+00:00 2015-02-11 02:57:35+00:00   242905092   \n",
       "181    2008-10-04 05:01:13+00:00 2009-01-17 02:17:35+00:00   242905092   \n",
       "228    2010-03-30 23:17:01+00:00 2013-05-17 17:18:08+00:00   353050611   \n",
       "406    2013-05-17 17:18:08+00:00 2013-06-04 23:21:54+00:00   555539361   \n",
       "438    2013-09-21 02:19:49+00:00 2015-02-11 02:57:35+00:00   573859300   \n",
       "...                          ...                       ...         ...   \n",
       "560049 2008-09-21 02:21:00+00:00 2012-10-04 18:39:10+00:00   239914276   \n",
       "560229 2010-09-24 04:22:40+00:00 2012-11-26 21:51:34+00:00   386682567   \n",
       "560531 2007-03-11 22:08:59+00:00 2007-08-14 22:33:45+00:00   114394184   \n",
       "560736 2009-09-20 19:42:22+00:00 2011-10-08 12:21:48+00:00   315150259   \n",
       "561357 2011-04-10 20:20:03+00:00 2011-11-20 20:34:00+00:00   423393978   \n",
       "\n",
       "              user_name     user_id       user_ip  \\\n",
       "177             Jackal4   1776444.0          None   \n",
       "181             Jackal4   1776444.0          None   \n",
       "228                None         NaN  24.208.75.32   \n",
       "406     Trut-h-urts man   8334148.0          None   \n",
       "438                None         NaN  69.117.59.46   \n",
       "...                 ...         ...           ...   \n",
       "560049         DinoBot2   7128788.0          None   \n",
       "560229  Rich Farmbrough     82835.0          None   \n",
       "560531           Mellum     45569.0          None   \n",
       "560736     Plasticspork  10068830.0          None   \n",
       "561357        Markussep     96340.0          None   \n",
       "\n",
       "                                               attributes isTypo  swear  \n",
       "177     {'stat2label': '[[Home run]]s', 'image': 'Repl...   True      0  \n",
       "181     {'stat2label': '[[Home run]]s', 'image': 'Repl...   True      0  \n",
       "228     {'stat2label': '[[Home run]]s', 'image': '0007...   True      0  \n",
       "406     {'stat2label': '[[Hit (baseball)|Hit]]s', 'ima...   True      0  \n",
       "438     {'stat2label': '[[Hit (baseball)|Hit]]s', 'ima...   True      0  \n",
       "...                                                   ...    ...    ...  \n",
       "560049  {'cover': 'SOASOB_Better.jpg', 'reviews': '* [...   True      0  \n",
       "560229  {'cityofbirth': '[[Blackpool]]', 'youthclubs1'...   True      0  \n",
       "560531  {'next': '[[A Bullet for Bullock]]', 'image': ...   True      0  \n",
       "560736  {'official_name': 'Comune di Castellabate', 'p...   True      0  \n",
       "561357  {'area_municunit': '127.6', 'city_seal': '', '...   True      0  \n",
       "\n",
       "[3150 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pageTitle</th>\n",
       "      <th>pageID</th>\n",
       "      <th>key</th>\n",
       "      <th>template</th>\n",
       "      <th>name</th>\n",
       "      <th>previousValue</th>\n",
       "      <th>currentValue</th>\n",
       "      <th>validFrom</th>\n",
       "      <th>validTo</th>\n",
       "      <th>revisionId</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>attributes</th>\n",
       "      <th>isTypo</th>\n",
       "      <th>swear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>stat1label</td>\n",
       "      <td>[[Batting Average]]</td>\n",
       "      <td>[[Batting average]]</td>\n",
       "      <td>2008-10-04 05:01:13+00:00</td>\n",
       "      <td>2015-02-11 02:57:35+00:00</td>\n",
       "      <td>242905092</td>\n",
       "      <td>Jackal4</td>\n",
       "      <td>1776444.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'stat2label': '[[Home run]]s', 'image': 'Repl...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>position</td>\n",
       "      <td>Right Fielder</td>\n",
       "      <td>Right fielder</td>\n",
       "      <td>2008-10-04 05:01:13+00:00</td>\n",
       "      <td>2009-01-17 02:17:35+00:00</td>\n",
       "      <td>242905092</td>\n",
       "      <td>Jackal4</td>\n",
       "      <td>1776444.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'stat2label': '[[Home run]]s', 'image': 'Repl...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>position</td>\n",
       "      <td>[[Right fielder]]</td>\n",
       "      <td>[[Right Fielder]]</td>\n",
       "      <td>2010-03-30 23:17:01+00:00</td>\n",
       "      <td>2013-05-17 17:18:08+00:00</td>\n",
       "      <td>353050611</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.208.75.32</td>\n",
       "      <td>{'stat2label': '[[Home run]]s', 'image': '0007...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>position</td>\n",
       "      <td>[[Right Fielder]]</td>\n",
       "      <td>[[Right fielder]]</td>\n",
       "      <td>2013-05-17 17:18:08+00:00</td>\n",
       "      <td>2013-06-04 23:21:54+00:00</td>\n",
       "      <td>555539361</td>\n",
       "      <td>Trut-h-urts man</td>\n",
       "      <td>8334148.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'stat2label': '[[Hit (baseball)|Hit]]s', 'ima...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Nelson Cruz</td>\n",
       "      <td>6159471</td>\n",
       "      <td>149830852-0</td>\n",
       "      <td>infobox mlb player</td>\n",
       "      <td>bats</td>\n",
       "      <td>right</td>\n",
       "      <td>Right</td>\n",
       "      <td>2013-09-21 02:19:49+00:00</td>\n",
       "      <td>2015-02-11 02:57:35+00:00</td>\n",
       "      <td>573859300</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.117.59.46</td>\n",
       "      <td>{'stat2label': '[[Hit (baseball)|Hit]]s', 'ima...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560049</th>\n",
       "      <td>Sunrise over a Sea of Blood</td>\n",
       "      <td>6135665</td>\n",
       "      <td>66094180-0</td>\n",
       "      <td>infobox album</td>\n",
       "      <td>reviews</td>\n",
       "      <td>* [[Jesus Freak Hideout]] {{rating-5|3.5}} &lt;re...</td>\n",
       "      <td>* [[Jesus Freak Hideout]] {{Rating|3.5|5}} &lt;re...</td>\n",
       "      <td>2008-09-21 02:21:00+00:00</td>\n",
       "      <td>2012-10-04 18:39:10+00:00</td>\n",
       "      <td>239914276</td>\n",
       "      <td>DinoBot2</td>\n",
       "      <td>7128788.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cover': 'SOASOB_Better.jpg', 'reviews': '* [...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560229</th>\n",
       "      <td>Ciaran Donnelly</td>\n",
       "      <td>6174068</td>\n",
       "      <td>75276638-0</td>\n",
       "      <td>infobox football biography 2</td>\n",
       "      <td>dateofbirth</td>\n",
       "      <td>{{birth date and age|1984|4|2|df=yes}}</td>\n",
       "      <td>{{Birth date and age|1984|4|2|df=yes}}</td>\n",
       "      <td>2010-09-24 04:22:40+00:00</td>\n",
       "      <td>2012-11-26 21:51:34+00:00</td>\n",
       "      <td>386682567</td>\n",
       "      <td>Rich Farmbrough</td>\n",
       "      <td>82835.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cityofbirth': '[[Blackpool]]', 'youthclubs1'...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560531</th>\n",
       "      <td>Sideshow (The Adventures of Batman &amp; Robin)</td>\n",
       "      <td>6188523</td>\n",
       "      <td>66733552-0</td>\n",
       "      <td>infobox television episode</td>\n",
       "      <td>next</td>\n",
       "      <td>[[A Bullet For Bullock]]</td>\n",
       "      <td>[[A Bullet for Bullock]]</td>\n",
       "      <td>2007-03-11 22:08:59+00:00</td>\n",
       "      <td>2007-08-14 22:33:45+00:00</td>\n",
       "      <td>114394184</td>\n",
       "      <td>Mellum</td>\n",
       "      <td>45569.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'next': '[[A Bullet for Bullock]]', 'image': ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560736</th>\n",
       "      <td>Castellabate</td>\n",
       "      <td>6125780</td>\n",
       "      <td>101811542-0</td>\n",
       "      <td>infobox cityit</td>\n",
       "      <td>population_as_of</td>\n",
       "      <td>[[december 31]], [[2004]]</td>\n",
       "      <td>December 31, 2004</td>\n",
       "      <td>2009-09-20 19:42:22+00:00</td>\n",
       "      <td>2011-10-08 12:21:48+00:00</td>\n",
       "      <td>315150259</td>\n",
       "      <td>Plasticspork</td>\n",
       "      <td>10068830.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'official_name': 'Comune di Castellabate', 'p...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561357</th>\n",
       "      <td>Konistres</td>\n",
       "      <td>6162857</td>\n",
       "      <td>308710087-0</td>\n",
       "      <td>infobox greek dimos</td>\n",
       "      <td>periph</td>\n",
       "      <td>[[Central Greece (periphery)|Central Greece]]</td>\n",
       "      <td>[[Central Greece Periphery|Central Greece]]</td>\n",
       "      <td>2011-04-10 20:20:03+00:00</td>\n",
       "      <td>2011-11-20 20:34:00+00:00</td>\n",
       "      <td>423393978</td>\n",
       "      <td>Markussep</td>\n",
       "      <td>96340.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'area_municunit': '127.6', 'city_seal': '', '...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3150 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Swear words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def check_swear(str1, str2, words_dict, lowercase=True):\n",
    "    \"\"\" Check if swear got added or removed.\n",
    "        Input:\n",
    "            str1: prev string\n",
    "            str2: curr string\n",
    "        Output:\n",
    "        prev false , curr true : 1 (swear word added)\n",
    "        prev true , curr false : 2 (swear word removed)\n",
    "    \"\"\"\n",
    "    if lowercase:\n",
    "        str1=str1.lower()\n",
    "        str2=str2.lower()\n",
    "\n",
    "    str1_lst=str1.split()\n",
    "    str2_lst=str2.split()\n",
    "\n",
    "    prev_swear=False\n",
    "    curr_swear=False\n",
    "    for string in str1_lst:\n",
    "        if word_in_dict(string, words_dict):\n",
    "            prev_swear=True\n",
    "            break\n",
    "\n",
    "    for string in str2_lst:\n",
    "        if word_in_dict(string, words_dict):\n",
    "            curr_swear=True\n",
    "            break\n",
    "\n",
    "    if (not prev_swear and curr_swear):\n",
    "        # swear word added\n",
    "        return 1\n",
    "    if (prev_swear and not curr_swear):\n",
    "        # swear word removed\n",
    "        return 2\n",
    "    if (prev_swear and  curr_swear):\n",
    "        # swear word in both\n",
    "        return 3\n",
    "    if (not prev_swear and not curr_swear):\n",
    "        # swear word in none\n",
    "        return 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "swear_file = open(\"../../../words_swear.txt\", \"r\")\n",
    "swear_dict = set(swear_file.read().split(\"\\n\"))\n",
    "swear_dict.remove(\"nazi\") # nazi is mostly no swear word in the context\n",
    "\n",
    "def is_not_empty_or_none(input):\n",
    "    return input is not None and input is not \"\"\n",
    "\n",
    "\n",
    "swear_lst = []\n",
    "for i in tqdm(range(len(change_tuples))):\n",
    "    if(is_not_empty_or_none(change_tuples[i][5]) and is_not_empty_or_none(change_tuples[i][6])):\n",
    "        swear_lst.append(check_swear(\n",
    "            change_tuples[i][5], change_tuples[i][6], swear_dict))\n",
    "    else:\n",
    "        swear_lst.append(None)\n",
    "\n",
    "\n",
    "counts_swear = {\"Swearwords added\": 0,\n",
    "                \"Swearwords removed\": 0,\n",
    "                \"Swearwords not touched\": 0,\n",
    "                \"Swearwords not found\": 0,\n",
    "                \"create or delete (skipped)\": 0}\n",
    "for test in swear_lst:\n",
    "    if test is 1:\n",
    "        counts_swear[\"Swearwords added\"] += 1\n",
    "    if test is 2:\n",
    "        counts_swear[\"Swearwords removed\"] += 1\n",
    "    if test is 3:\n",
    "        counts_swear[\"Swearwords not touched\"] += 1\n",
    "    if test is 0:\n",
    "        counts_swear[\"Swearwords not found\"] += 1\n",
    "    if test is None:\n",
    "        # prev or curr is None\n",
    "        counts_swear[\"create or delete (skipped)\"] += 1\n",
    "print(counts_swear)\n",
    "\n",
    "idx_swear = [[], []]\n",
    "for i in range(len(swear_lst)):\n",
    "    if swear_lst[i] == 1:\n",
    "        idx_swear[0].append(i)\n",
    "    if swear_lst[i] == 2:\n",
    "        idx_swear[1].append(i)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Swearwords added:\", counts_swear[\"Swearwords added\"])\n",
    "print(\"Swearwords removed:\", counts_swear[\"Swearwords removed\"])\n",
    "print(\"Swearwords not touched:\", counts_swear[\"Swearwords not touched\"])\n",
    "print(\"Swearwords not found:\", counts_swear[\"Swearwords not found\"])\n",
    "print(\"create or delete (skipped):\", counts_swear[\"create or delete (skipped)\"])\n",
    "edit_count = counts_swear[\"Swearwords added\"]+counts_swear[\"Swearwords removed\"] + \\\n",
    "    counts_swear[\"Swearwords not touched\"]+counts_swear[\"Swearwords not found\"]\n",
    "print(\"Toal tuples (only updates without creations/deletions):\", edit_count)\n",
    "print(\"Toal tuples:\", edit_count+counts_swear[\"create or delete (skipped)\"])\n",
    "print(\"Percentage of swear words in edits (only updates without creations/deletions) added and removed:\",\n",
    "      counts_swear[\"Swearwords added\"]/edit_count, counts_swear[\"Swearwords removed\"]/edit_count)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Swear words added"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_deltas_swear = timedeltas_between_changes(idx_swear[0], change_tuples)\n",
    "time_deltas_swear = np.array(time_deltas_swear)\n",
    "print(\"Average Time to change for a typofix\")\n",
    "print(\"Median time in days\", np.median(timedelta_to_days(time_deltas_swear)))\n",
    "print(\"Median time in hours\", np.median(timedelta_to_hours(time_deltas_swear)))\n",
    "print(\"Median time in seconds\", np.median(timedelta_to_seconds(time_deltas_swear)))\n",
    "print(\"timedelta mean and std in days:\", np.mean(\n",
    "    timedelta_to_days(time_deltas_swear)), np.std(timedelta_to_days(time_deltas_swear)))\n",
    "print(\"timedelta mean:\", str(time_deltas_swear.mean()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def removeOutliers(data, percentile):\n",
    "    lower_quartile = np.percentile(data, percentile)\n",
    "    upper_quartile = np.percentile(data, 100-percentile)\n",
    "    if lower_quartile == upper_quartile:\n",
    "        return data\n",
    "    print(lower_quartile, upper_quartile)\n",
    "    data = data[data >= lower_quartile]\n",
    "    data = data[data < upper_quartile]\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.iloc[idx_swear[0]].head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Swear words removed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.iloc[idx_swear[1]].head(10)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('mp': conda)"
  },
  "interpreter": {
   "hash": "9d6890af0e7111529245105513a4571ecfc3e378a026bfe7b711a2eb3eb8eca5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}