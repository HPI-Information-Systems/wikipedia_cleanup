{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36734d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "from wikipedia_cleanup.data_filter import KeepAttributesDataFilter, generate_default_filters\n",
    "from wikipedia_cleanup.predict import TrainAndPredictFramework\n",
    "from wikipedia_cleanup.predictor import ZeroPredictor, OnePredictor, MeanPredictor, RandomPredictor, LastChangePredictor\n",
    "from wikipedia_cleanup.property_correlation import PropertyCorrelationPredictor\n",
    "from wikipedia_cleanup.random_forest import RandomForestPredictor\n",
    "from wikipedia_cleanup.ensemble import OrEnsemble, AndEnsemble, AverageEnsemble\n",
    "from wikipedia_cleanup.ar import AssociationRulesTemplatePredictor, AssociationRulesPredictor, AssociationRulesInfoboxPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc94e1-7c75-46d3-a6b2-fd6a86447e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from wikipedia_cleanup.utils import result_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1626ec-9b02-423e-8a04-7dc59da2f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = 10\n",
    "n_jobs = 4\n",
    "input_path = Path(\"/run/media/secret/manjaro-home/secret/mp-data/new_costum_filtered_format_with_features\")\n",
    "input_path = Path(\"../../data/new_costum_filtered_format_with_features/\")\n",
    "#model = PropertyCorrelationPredictor(use_cache=True)\n",
    "#model = RandomForestPredictor(use_cache=True)\n",
    "# model = MeanPredictor()\n",
    "# MeanPredictor(), LastChangePredictor()\n",
    "predictors = [AssociationRulesTemplatePredictor(), AssociationRulesInfoboxPredictor(), AssociationRulesPredictor()]#, \n",
    "\n",
    "#model = AveragingEnsemble(predictors)\n",
    "model = OrEnsemble(predictors)\n",
    "model = AndEnsemble(predictors)\n",
    "#model = AverageEnsemble(predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2589b70-696e-4d9a-90bd-4f97e4d892a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_date = datetime(2018, 9, 1)\n",
    "predictor_train_date = test_start_date - timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee69d9e-a8e8-410c-ac1c-dfce51a97153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predictors(predictor_train_date, run_id):\n",
    "    predictions = []\n",
    "    for model in predictors:\n",
    "        framework = TrainAndPredictFramework(model, group_key=['infobox_key', 'property_name'], run_id=run_id, test_start_date = predictor_train_date)\n",
    "        framework.load_data(input_path, n_files, n_jobs)\n",
    "        framework.fit_model()\n",
    "        framework.test_model(predict_subset=1, save_results=False)\n",
    "        predictions.append(framework.run_results['predictions'])\n",
    "        keys = framework.run_results['keys']\n",
    "        labels = framework.run_results['labels']\n",
    "        print(\"------------------------------------------------\")\n",
    "    return predictions, labels, keys\n",
    "\n",
    "def generate_features():\n",
    "    feature_map = dict()\n",
    "    key_column_idx = framework.data.columns.tolist().index('key')\n",
    "    for key, group in itertools.groupby(\n",
    "        framework.data[framework.data[\"value_valid_from\"] < framework.test_start_date].to_numpy(), lambda x: x[key_column_idx]\n",
    "    ):\n",
    "        feature_map[key] = sum(1 for x in group)\n",
    "    return np.vectorize(feature_map.get)(keys, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208701c7-9686-4b10-837b-e35eb3285734",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, keys = fit_predictors(predictor_train_date, run_id=\"Ensemble_subset_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5c552-b7f1-4ffd-857f-52410e5737bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = result_directory() / 'Ensemble_training_predictions'\n",
    "out_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f44504-8ca5-4133-b55b-1e42ec64beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cache\n",
    "with open(out_path / 'predictions.pickle', \"wb\") as f:\n",
    "    pickle.dump({'keys' : keys, 'labels': labels, 'predictions': predictions},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e667e-40bf-401f-a4df-4e51ee7b5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cache\n",
    "with open(out_path / 'predictions.pickle', \"rb\") as f:\n",
    "    cache = pickle.load(f)\n",
    "    predictions = cache['predictions']\n",
    "    keys = cache['keys']\n",
    "    labels = cache['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937c66a-76af-43e4-bcae-29bb6f534d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = TrainAndPredictFramework(model, group_key=['infobox_key', 'property_name'], run_id=\"finished_ensemble\", test_start_date = predictor_train_date)\n",
    "framework.load_data(input_path, n_files, n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f481ad6-d744-4b86-8d50-7584d7839d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_samples = generate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220aafd-bacf-4b96-ac04-81eaf60eb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles = []\n",
    "for i in tqdm(range(len(framework.testing_timeframes))):\n",
    "    current_predictions = np.array([predictions[x][i] for x in range(len(predictors))], dtype=bool)\n",
    "    current_predictions = np.vstack((current_predictions, n_training_samples[:, None].repeat(current_predictions.shape[2], axis=1)[None, ...]))\n",
    "    current_predictions = current_predictions.reshape(current_predictions.shape[0], -1).T\n",
    "    current_labels = np.array(labels[i], dtype=bool).reshape(-1)\n",
    "    \n",
    "    ensemble = LogisticRegression()\n",
    "    ensemble.fit(current_predictions, current_labels)\n",
    "    ensembles.append(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a5eea-bc3e-4669-b418-745923906e54",
   "metadata": {},
   "source": [
    "## Evaluation code\n",
    "Later cells only work for 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427ba38-f83c-4d0c-b343-941547e87f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ensembles[0].coef_)\n",
    "print(ensembles[1].coef_)\n",
    "print(ensembles[2].coef_)\n",
    "print(ensembles[3].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c740e-294d-4502-bc20-335fd7692abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe = 0\n",
    "step = 5\n",
    "predictions = list(range(0,700,step))\n",
    "preds = []\n",
    "\n",
    "for k, v in [(0,0), (0,1), (1,0), (1,1)]:\n",
    "    current_preds = []\n",
    "    for i in predictions:\n",
    "        current_preds.append(ensembles[timeframe].predict_proba(np.array([k,v, i])[None, :])[0,1])\n",
    "    preds.append(current_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf931d-4cd4-4fd7-a0f4-880614c773f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(preds).T)\n",
    "plt.legend(['no pred', 'regression', 'correlation', 'both'])\n",
    "plt.xticks(ticks=np.array(predictions[::10])/step, labels=predictions[::10])\n",
    "plt.ylabel(\"% change\")\n",
    "plt.xlabel(\"num changes in train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0214b1b-a856-4e7a-b1aa-62aebe570e02",
   "metadata": {},
   "source": [
    "# Test the ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca118598-ee8c-442a-861d-679ae475e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, keys = fit_predictors(test_start_date, run_id=\"Ensemble_full_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab236d4-47c4-475d-951e-d7f15c57dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = result_directory() / 'Ensemble_testing_predictions'\n",
    "out_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26344b9e-27df-43a4-b006-33804ab38b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cache\n",
    "with open(out_path / 'predictions.pickle', \"wb\") as f:\n",
    "    pickle.dump({'keys' : keys, 'labels': labels, 'predictions': predictions, 'ensembles': ensembles},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebb4d6-58e8-4aa8-aa52-45897a341edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cache\n",
    "with open(out_path / 'predictions.pickle', \"rb\") as f:\n",
    "    cache = pickle.load(f)\n",
    "    predictions = cache['predictions']\n",
    "    keys = cache['keys']\n",
    "    labels = cache['labels']\n",
    "    ensembles = cache['ensembles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eccdb4-c6bd-4602-8bb4-c41d78e1b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = TrainAndPredictFramework(model, group_key=['infobox_key', 'property_name'], run_id=\"finished_ensemble\", test_start_date = test_start_date)\n",
    "framework.load_data(input_path, n_files, n_jobs)\n",
    "\n",
    "n_training_samples = generate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1fc3b-3038-4b44-aa70-e2f45dc39f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictions = []   \n",
    "for i in tqdm(range(len(framework.testing_timeframes))):\n",
    "    current_predictions = np.array([predictions[x][i] for x in range(len(predictors))], dtype=bool)\n",
    "    current_predictions = np.vstack((current_predictions, n_training_samples[:, None].repeat(current_predictions.shape[2], axis=1)[None, ...]))\n",
    "    current_predictions = current_predictions.reshape(current_predictions.shape[0], -1).T\n",
    "    current_labels = np.array(labels[i], dtype=bool).reshape(-1)\n",
    "    \n",
    "    ensemble = ensembles[i]\n",
    "    ensemble_predictions.append(ensemble.predict_proba(current_predictions)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d2bab-c7d1-443b-858c-90abb3c7a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_ensemble_predictions = []\n",
    "threshold = 0.5\n",
    "for i in range(len(framework.testing_timeframes)):\n",
    "    thresholded_ensemble_predictions.append(ensemble_predictions[i].reshape(predictions[0][i].shape) > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c8726-1021-42e9-a16f-1fed14ae2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_ensemble_predictions = thresholded_ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae78c7-9428-41a4-965f-85f2e129c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run_results = {'keys' : keys, 'labels': labels, 'predictions': thresholded_ensemble_predictions}\n",
    "framework.run_results = new_run_results\n",
    "try:\n",
    "    framework.data[\"value_valid_from\"] = framework.data[\"value_valid_from\"].dt.date\n",
    "except AttributeError:\n",
    "    pass\n",
    "print(framework._evaluate_predictions(thresholded_ensemble_predictions, labels[0]))\n",
    "framework.generate_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e306b33-e916-497a-98bd-9f763f55741d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
