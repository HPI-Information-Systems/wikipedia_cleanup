{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4da73e-e3eb-4a2c-a06b-28f566f49493",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker as tck\n",
    "import seaborn as sns\n",
    "import ipywidgets\n",
    "import pydantic\n",
    "import typing\n",
    "import datetime\n",
    "import itertools\n",
    "import collections\n",
    "import json\n",
    "import gzip\n",
    "import tqdm\n",
    "import multiprocessing\n",
    "from efficient_apriori import apriori\n",
    "import math\n",
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, \"de_DE\")\n",
    "locale._override_localeconv[\"thousands_sep\"] = \".\"\n",
    "locale._override_localeconv[\"grouping\"] = [3, 3, 0]\n",
    "plt.rcParams[\"axes.formatter.use_locale\"] = True\n",
    "sns.set_theme(style=\"ticks\")\n",
    "cm = 1 / 2.54\n",
    "a4 = 29.7, 42\n",
    "\n",
    "\n",
    "class InfoboxProperty(pydantic.BaseModel):\n",
    "    propertyType: typing.Optional[str]\n",
    "    name: str\n",
    "\n",
    "\n",
    "class InfoboxChange(pydantic.BaseModel):\n",
    "    property: InfoboxProperty\n",
    "    valueValidTo: typing.Optional[datetime.datetime] = None\n",
    "    currentValue: typing.Optional[str] = None\n",
    "    previousValue: typing.Optional[str] = None\n",
    "\n",
    "\n",
    "class User(pydantic.BaseModel):\n",
    "    username: typing.Optional[str]\n",
    "    id: typing.Optional[int]\n",
    "\n",
    "\n",
    "class InfoboxRevision(pydantic.BaseModel):\n",
    "    revisionId: int\n",
    "    pageTitle: str\n",
    "    changes: typing.Sequence[InfoboxChange]\n",
    "    validFrom: datetime.datetime\n",
    "    attributes: typing.Optional[typing.Dict[str, str]]\n",
    "    pageID: int\n",
    "    revisionType: typing.Optional[str]\n",
    "    key: str\n",
    "    template: typing.Optional[str] = None\n",
    "    position: typing.Optional[int] = None\n",
    "    user: typing.Optional[User] = None\n",
    "    validTo: typing.Optional[datetime.datetime] = None\n",
    "\n",
    "\n",
    "class ChangeBuckets(pydantic.BaseModel):\n",
    "    filename: str\n",
    "    changes: typing.Dict[str, typing.Sequence[typing.Hashable]]\n",
    "\n",
    "\n",
    "def sliding(seq, window_size):\n",
    "    for i in range(len(seq) - window_size + 1):\n",
    "        yield seq[i : i + window_size]\n",
    "\n",
    "\n",
    "def overlapping_groups(groups, window_size):\n",
    "    return {\n",
    "        keys[0]: set().union(*(groups[key] for key in keys))\n",
    "        for keys in sliding(tuple(groups.keys()), window_size)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dafdd18-b18e-4726-a5f2-83eaf05cf7b3",
   "metadata": {},
   "source": [
    "# Creating Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cb9f0-c60c-4130-bdc2-98ad5723f785",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_pageid(file):\n",
    "    groups = collections.defaultdict(set)\n",
    "    with open(file) as f:\n",
    "        revisions = (InfoboxRevision.parse_raw(line) for line in f)\n",
    "        for revision in revisions:\n",
    "            groups[revision.validFrom.date().isoformat()].add(revision.pageID)\n",
    "    return ChangeBuckets(\n",
    "        filename=file.name,\n",
    "        changes={k: tuple(sorted(groups[k])) for k in sorted(groups.keys())},\n",
    "    )\n",
    "\n",
    "\n",
    "def process_property(file):\n",
    "    groups = collections.defaultdict(set)\n",
    "    with open(file) as f:\n",
    "        revisions = (InfoboxRevision.parse_raw(line) for line in f)\n",
    "        for revision in revisions:\n",
    "            groups[revision.validFrom.date().isoformat()].update(\n",
    "                change.property.name for change in revision.changes\n",
    "            )\n",
    "    return ChangeBuckets(\n",
    "        filename=file.name,\n",
    "        changes={k: tuple(sorted(groups[k])) for k in sorted(groups.keys())},\n",
    "    )\n",
    "\n",
    "\n",
    "def process_template_property(file):\n",
    "    groups = collections.defaultdict(set)\n",
    "    with open(file) as f:\n",
    "        revisions = (InfoboxRevision.parse_raw(line) for line in f)\n",
    "        for revision in revisions:\n",
    "            groups[revision.validFrom.date().isoformat()].update(\n",
    "                (str(revision.template), change.property.name)\n",
    "                for change in revision.changes\n",
    "            )\n",
    "    return ChangeBuckets(\n",
    "        filename=file.name,\n",
    "        changes={k: tuple(sorted(groups[k])) for k in sorted(groups.keys())},\n",
    "    )\n",
    "\n",
    "\n",
    "def process_page_property(file):\n",
    "    groups = collections.defaultdict(set)\n",
    "    with open(file) as f:\n",
    "        revisions = (InfoboxRevision.parse_raw(line) for line in f)\n",
    "        for revision in revisions:\n",
    "            groups[revision.validFrom.date().isoformat()].update(\n",
    "                (revision.pageID, change.property.name) for change in revision.changes\n",
    "            )\n",
    "    return ChangeBuckets(\n",
    "        filename=file.name,\n",
    "        changes={k: tuple(sorted(groups[k])) for k in sorted(groups.keys())},\n",
    "    )\n",
    "\n",
    "\n",
    "fname = \"./changesets-pageid.json.gz\"\n",
    "\n",
    "if not Path(fname).exists():\n",
    "    groups = collections.defaultdict(set)\n",
    "    files = [\n",
    "        x\n",
    "        for x in sorted(\n",
    "            Path(\"../../matched-infoboxes-extracted/\").rglob(\"*.output.json\")\n",
    "        )\n",
    "        if x.is_file()\n",
    "    ]\n",
    "    with multiprocessing.Pool(4) as p:\n",
    "        imap = p.imap(process_page_property, files)\n",
    "        for cb in tqdm.tqdm(imap, total=len(files)):\n",
    "            for k, v in cb.changes.items():\n",
    "                groups[k].update(v)\n",
    "    del files\n",
    "    groups = {k: tuple(sorted(groups[k])) for k in sorted(groups.keys())}\n",
    "    with open(fname, \"wb\") as f:\n",
    "        f.write(\n",
    "            gzip.compress(\n",
    "                ChangeBuckets(filename=\"all\", changes=groups)\n",
    "                .json(indent=None, separators=(\",\", \":\"))\n",
    "                .encode(\"utf-8\")\n",
    "            )\n",
    "        )\n",
    "else:\n",
    "    with open(fname, \"rb\") as f:\n",
    "        groups = ChangeBuckets.parse_raw(\n",
    "            gzip.decompress(f.read()).decode(\"utf-8\")\n",
    "        ).changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83854a59-d3c0-4866-af72-f646282df8c1",
   "metadata": {},
   "source": [
    "## Min/Max Support Filtering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a55b6-6cff-4108-a84d-afaff95fdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = collections.defaultdict(int)\n",
    "for bucket in groups.values():\n",
    "    for id in bucket:\n",
    "        freqs[id] += 1\n",
    "\n",
    "freqs = pd.DataFrame(freqs.items(), columns=[\"ID\", \"Count\"])\n",
    "freqs[\"Frequency\"] = freqs[\"Count\"] / len(groups)\n",
    "freqs.sort_values(\"Frequency\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663f035-0b50-455a-a4a1-88cfa5da8bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ipywidgets.interact(\n",
    "    bins=ipywidgets.IntSlider(\n",
    "        value=50, min=5, max=100, step=5, continuous_update=False\n",
    "    ),\n",
    "    lower=ipywidgets.FloatSlider(\n",
    "        value=0.001,\n",
    "        min=0.0,\n",
    "        max=1.0,\n",
    "        step=0.001,\n",
    "        readout_format=\".1%\",\n",
    "        continuous_update=False,\n",
    "    ),\n",
    "    upper=ipywidgets.FloatSlider(\n",
    "        value=0.1,\n",
    "        min=0.0,\n",
    "        max=1.0,\n",
    "        step=0.001,\n",
    "        readout_format=\".1%\",\n",
    "        continuous_update=False,\n",
    "    ),\n",
    ")\n",
    "def plot_frequency_hist(bins, lower, upper):\n",
    "    fig = plt.figure(figsize=(20 * cm, 15 * cm), dpi=100)\n",
    "    ax = plt.subplot(111)\n",
    "    freqs[\"Filtered\"] = (freqs[\"Frequency\"] < lower) | (freqs[\"Frequency\"] > upper)\n",
    "    sns.histplot(\n",
    "        data=freqs,\n",
    "        x=\"Frequency\",\n",
    "        hue=\"Filtered\",\n",
    "        stat=\"percent\",\n",
    "        bins=bins,\n",
    "        multiple=\"stack\",\n",
    "        log_scale=(False, True),\n",
    "        ax=ax,\n",
    "    )\n",
    "    sns.move_legend(\n",
    "        ax,\n",
    "        \"center left\",\n",
    "        bbox_to_anchor=(1, 0.5),\n",
    "        ncol=1,\n",
    "        frameon=False,\n",
    "    )\n",
    "    ax.annotate(\n",
    "        f\"Filtered: {freqs['Filtered'].sum() / len(freqs):.2%} IDs\",\n",
    "        xy=(1, 1),\n",
    "        xycoords=\"axes fraction\",\n",
    "        xytext=(0, 0),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax.xaxis.set_major_formatter(tck.PercentFormatter(xmax=1))\n",
    "    ax.yaxis.set_major_formatter(tck.PercentFormatter(xmax=100, decimals=4))\n",
    "    sns.despine(ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f517a8-15ed-4290-98c9-d9fec522c864",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Apriori Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebca635-7318-45cf-b15e-f3c1b84d84b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_days = 5\n",
    "data = tuple(overlapping_groups(groups, n_days).values())\n",
    "test_size = math.ceil(len(data) * 0.2)\n",
    "train_data = data[: len(data) - test_size]\n",
    "test_data = data[len(data) - test_size :]\n",
    "del data, test_size\n",
    "itemsets, rules = apriori(\n",
    "    train_data,\n",
    "    min_support=0.01 * n_days,\n",
    "    min_confidence=0.85,\n",
    "    max_length=4,\n",
    ")\n",
    "del n_days\n",
    "\n",
    "df = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                frozenset(rule.lhs),\n",
    "                frozenset(rule.rhs),\n",
    "                rule.confidence,\n",
    "                rule.support,\n",
    "                rule.lift,\n",
    "                rule.conviction,\n",
    "            )\n",
    "            for rule in rules\n",
    "        ],\n",
    "        columns=[\"LHS\", \"RHS\", \"Confidence\", \"Support\", \"Lift\", \"Conviction\"],\n",
    "    )\n",
    "    .set_index([\"LHS\", \"RHS\"])\n",
    "    .sort_index()\n",
    ")\n",
    "display(df.describe().T.style.format(\"{:.2f}\"))\n",
    "display(df.sort_values(\"Lift\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d154d0-593f-4f43-a476-4371b5afca94",
   "metadata": {},
   "source": [
    "# Evaluation per Association Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b128e5d-6773-4a0f-9c8d-8ac997438717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in df.itertuples():\n",
    "    d = {(False, False): 0, (False, True): 0, (True, False): 0, (True, True): 0}\n",
    "    for s in test_data:\n",
    "        d[(i.Index[1] <= s, i.Index[0] <= s)] += 1\n",
    "    df.loc[i.Index, \"TN\"] = d[(False, False)]\n",
    "    df.loc[i.Index, \"FP\"] = d[(False, True)]\n",
    "    df.loc[i.Index, \"FN\"] = d[(True, False)]\n",
    "    df.loc[i.Index, \"TP\"] = d[(True, True)]\n",
    "df[[\"TP\", \"FP\", \"TN\", \"FN\"]] = df[[\"TP\", \"FP\", \"TN\", \"FN\"]].astype(int)\n",
    "df[\"Precision\"] = (df[\"TP\"] / (df[\"TP\"] + df[\"FP\"])).fillna(0)\n",
    "df[\"Recall\"] = (df[\"TP\"] / (df[\"TP\"] + df[\"FN\"])).fillna(0)\n",
    "df[\"F1\"] = (\n",
    "    2 * (df[\"Precision\"] * df[\"Recall\"]) / (df[\"Precision\"] + df[\"Recall\"])\n",
    ").fillna(0)\n",
    "df[\"Accuracy\"] = (\n",
    "    (df[\"TP\"] + df[\"TN\"]) / df[[\"TP\", \"FP\", \"TN\", \"FN\"]].sum(axis=1)\n",
    ").fillna(0)\n",
    "\n",
    "df.sort_values([\"Precision\", \"F1\", \"Recall\", \"Accuracy\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a89ca-9332-4b02-adee-d310bdf73a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ipywidgets.interact(\n",
    "    x=ipywidgets.ToggleButtons(options=[\"Confidence\", \"Support\", \"Lift\"]),\n",
    "    y=ipywidgets.ToggleButtons(options=[\"Precision\", \"Recall\", \"F1\", \"Accuracy\"]),\n",
    "    support=ipywidgets.FloatRangeSlider(\n",
    "        value=(0.0, 1.0),\n",
    "        min=0.0,\n",
    "        max=1.0,\n",
    "        step=0.001,\n",
    "        readout_format=\".1%\",\n",
    "        continuous_update=False,\n",
    "    ),\n",
    "    confidence=ipywidgets.FloatRangeSlider(\n",
    "        value=(0.0, 1.0),\n",
    "        min=0.0,\n",
    "        max=1.0,\n",
    "        step=0.001,\n",
    "        readout_format=\".1%\",\n",
    "        continuous_update=False,\n",
    "    ),\n",
    "    q=ipywidgets.IntSlider(value=4, min=1, max=10, step=1, continuous_update=False),\n",
    ")\n",
    "def plot_correlation(x, y, support, confidence, q):\n",
    "    temp = df[\n",
    "        df[\"Support\"].between(*support) & df[\"Confidence\"].between(*confidence)\n",
    "    ].copy()\n",
    "    g = sns.jointplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        data=temp,\n",
    "        kind=\"hist\",\n",
    "        height=20 * cm,\n",
    "        ax=ax,\n",
    "    )\n",
    "    g.ax_joint.set_xlim(temp[x].min(), temp[x].max())\n",
    "    if x in {\"Confidence\", \"Support\"}:\n",
    "        g.ax_joint.xaxis.set_major_formatter(tck.PercentFormatter(xmax=1))\n",
    "    g.ax_joint.set_ylim(0, 1)\n",
    "    g.ax_joint.yaxis.set_major_formatter(tck.PercentFormatter(xmax=1))\n",
    "    plt.show()\n",
    "    temp[f\"{y} Interval\"] = pd.cut(\n",
    "        temp[y],\n",
    "        q,\n",
    "        labels=[f\"≤ {x[1]:.0%}\" for x in pd.interval_range(0, 1, q).to_tuples()],\n",
    "    )\n",
    "    g = sns.jointplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue=f\"{y} Interval\",\n",
    "        palette=sns.color_palette(\"mako\", n_colors=q),\n",
    "        data=temp,\n",
    "        kind=\"scatter\",\n",
    "        height=20 * cm,\n",
    "        ax=ax,\n",
    "        marginal_kws={\"common_norm\": False},\n",
    "    )\n",
    "    g.ax_joint.set_xlim(temp[x].min(), temp[x].max())\n",
    "    if x in {\"Confidence\", \"Support\"}:\n",
    "        g.ax_joint.xaxis.set_major_formatter(tck.PercentFormatter(xmax=1))\n",
    "    g.ax_joint.set_ylim(0, 1)\n",
    "    g.ax_joint.yaxis.set_major_formatter(tck.PercentFormatter(xmax=1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c1c4c7-4839-497f-ba82-22dcccf142da",
   "metadata": {},
   "source": [
    "# Evaluation per Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f019b-c698-4a5f-aa49-c8b96ef9f40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = (\n",
    "    df.reset_index()[[\"LHS\", \"RHS\"]]\n",
    "    .groupby(\"RHS\")[\"LHS\"]\n",
    "    .apply(lambda lhs: tuple(sorted(set(lhs))))\n",
    "    .reset_index()\n",
    "    .set_index(\"RHS\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "for i in df2.itertuples(index=True):\n",
    "    d = {(False, False): 0, (False, True): 0, (True, False): 0, (True, True): 0}\n",
    "    for s in test_data:\n",
    "        d[(i.Index in s, all((j in s) for j in i.LHS))] += 1\n",
    "    df2.loc[i.Index, \"TN\"] = d[(False, False)]\n",
    "    df2.loc[i.Index, \"FP\"] = d[(False, True)]\n",
    "    df2.loc[i.Index, \"FN\"] = d[(True, False)]\n",
    "    df2.loc[i.Index, \"TP\"] = d[(True, True)]\n",
    "df2[[\"TP\", \"FP\", \"TN\", \"FN\"]] = df2[[\"TP\", \"FP\", \"TN\", \"FN\"]].astype(int)\n",
    "df2[\"Precision\"] = (df2[\"TP\"] / (df2[\"TP\"] + df2[\"FP\"])).fillna(0)\n",
    "df2[\"Recall\"] = (df2[\"TP\"] / (df2[\"TP\"] + df2[\"FN\"])).fillna(0)\n",
    "df2[\"F1\"] = (\n",
    "    2 * (df2[\"Precision\"] * df2[\"Recall\"]) / (df2[\"Precision\"] + df2[\"Recall\"])\n",
    ").fillna(0)\n",
    "df2[\"Accuracy\"] = (\n",
    "    (df2[\"TP\"] + df2[\"TN\"]) / df2[[\"TP\", \"FP\", \"TN\", \"FN\"]].sum(axis=1)\n",
    ").fillna(0)\n",
    "\n",
    "display(df2.sort_values([\"F1\", \"Precision\", \"Recall\", \"Accuracy\"], ascending=False))\n",
    "\n",
    "print(\n",
    "    \"Predictor totals:\",\n",
    "    f'Precision: {locale.format_string(\"%.2f%%\", 100*df2[\"TP\"].sum() / (df2[\"TP\"].sum() + df2[\"FP\"].sum()), True)}',\n",
    "    f'Recall: {locale.format_string(\"%.2f%%\", 100*df2[\"TP\"].sum() / (df2[\"TP\"].sum() + df2[\"FN\"].sum()), True)}',\n",
    "    f'F1: {locale.format_string(\"%.2f%%\", 100*2*(df2[\"TP\"].sum() / (df2[\"TP\"].sum() + df2[\"FP\"].sum())*df2[\"TP\"].sum() / (df2[\"TP\"].sum() + df2[\"FN\"].sum()))/(df2[\"TP\"].sum() / (df2[\"TP\"].sum() + df2[\"FP\"].sum())+df2[\"TP\"].sum() / (df2[\"TP\"].sum() + df2[\"FN\"].sum())), True)}',\n",
    "    f'Accuracy: {locale.format_string(\"%.2f%%\", 100*(df2[\"TP\"].sum() + df2[\"TN\"].sum()) / df2[[\"TP\", \"FP\", \"TN\", \"FN\"]].sum().sum(), True)}',\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b7f8f-965c-4207-a885-96ac153ad63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_predictable = (\n",
    "    df2[[\"TP\", \"FP\", \"TN\", \"FN\"]].sum().sum()\n",
    ")  # == len(df2) * len(test_data)\n",
    "total_changes = sum(len(i) for i in test_data)\n",
    "print(\n",
    "    f'Changes predictable: {locale.format_string(\"%d\", changes_predictable, True)}',\n",
    "    f'Changes happened: {locale.format_string(\"%d\", total_changes, True)}',\n",
    "    f'--> {locale.format_string(\"%.2f%%\", 100 * changes_predictable / total_changes, True)}',\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
